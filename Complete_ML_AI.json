[{"Type":"Supervised - Classification","Algorithm":"Logistic Regression","Best Use Case":"Binary classification, baseline model","Key Fundamentals to Know":"Feature scaling, Linear relationship assumption","Libraries":"sklearn, statsmodels","Real-World Example":"Spam detection, Credit scoring","Hyperparameters to Tune":"C, penalty, solver","Speed (Training\/Prediction)":"Fast \/ Fast","Deployment Strategy":"Flask, FastAPI, ONNX","Complexity (Low\/Med\/High)":"Low","Evaluation Metric(s)":"Accuracy, AUC, F1","Higher or Lower":"Accuracy (Higher-is-Better), AUC (Higher-is-Better), F1 (Higher-is-Better)","What It Evaluates":"Evaluates classification correctness and separability","Evaluation Metrics":"Accuracy (Higher-is-Better) -  Correct predictions\nAUC (Higher-is-Better) -  Separability\nF1 (Higher-is-Better) -  Harmonic mean of precision and recall"},{"Type":"Supervised - Classification","Algorithm":"K-Nearest Neighbors (KNN)","Best Use Case":"Pattern recognition with few samples","Key Fundamentals to Know":"Distance metrics, Scaling required","Libraries":"sklearn","Real-World Example":"Recommendation systems, Handwriting recognition","Hyperparameters to Tune":"n_neighbors, weights","Speed (Training\/Prediction)":"Slow \/ Medium","Deployment Strategy":"Pickle, Streamlit","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Accuracy, Confusion Matrix","Higher or Lower":"Accuracy (Higher-is-Better)","What It Evaluates":"Prediction correctness and error breakdown","Evaluation Metrics":"Accuracy (Higher-is-Better) -  Correctness\nConfusion Matrix - TP, FP, TN, FN analysis"},{"Type":"Supervised - Classification","Algorithm":"Support Vector Machine (SVM)","Best Use Case":"High-dimensional data classification","Key Fundamentals to Know":"Kernel trick, Hyperplane separation","Libraries":"sklearn","Real-World Example":"Text classification, Image recognition","Hyperparameters to Tune":"C, kernel, gamma","Speed (Training\/Prediction)":"Slow \/ Medium","Deployment Strategy":"ONNX, FastAPI","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"Accuracy, ROC AUC","Higher or Lower":"Accuracy (Higher-is-Better), ROC AUC (Higher-is-Better)","What It Evaluates":"Class separability and accuracy","Evaluation Metrics":"Accuracy (Higher-is-Better) -  Correctness\nROC AUC (Higher-is-Better) -  Threshold-independent separation"},{"Type":"Supervised - Classification","Algorithm":"Decision Tree Classifier","Best Use Case":"Interpretable rule-based model","Key Fundamentals to Know":"Overfitting control, Feature importance","Libraries":"sklearn","Real-World Example":"Loan approval, Customer churn","Hyperparameters to Tune":"max_depth, min_samples_split","Speed (Training\/Prediction)":"Medium \/ Fast","Deployment Strategy":"Flask, Pickle","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Accuracy, Gini","Higher or Lower":"Accuracy (Higher-is-Better), Gini (Lower-is-Better)","What It Evaluates":"Correct predictions and split impurity","Evaluation Metrics":"Accuracy (Higher-is-Better) -  Correct classification\nGini(Lower-is-Better) - Split quality"},{"Type":"Supervised - Classification","Algorithm":"Random Forest Classifier","Best Use Case":"Robust ensemble of trees","Key Fundamentals to Know":"Bagging, Feature randomness","Libraries":"sklearn.ensemble","Real-World Example":"Fraud detection, Disease diagnosis","Hyperparameters to Tune":"n_estimators, max_depth, max_features","Speed (Training\/Prediction)":"Medium \/ Fast","Deployment Strategy":"Docker, MLflow","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Accuracy, AUC","Higher or Lower":"Accuracy (Higher-is-Better), AUC (Higher-is-Better)","What It Evaluates":"Improved stability and performance","Evaluation Metrics":"Accuracy (Higher-is-Better) -  Overall correctness\nAUC (Higher-is-Better) -  Separability measure"},{"Type":"Supervised - Classification","Algorithm":"Gradient Boosting Classifier","Best Use Case":"Boosted trees for improved accuracy","Key Fundamentals to Know":"Sequential learning, Learning rate tuning","Libraries":"xgboost, lightgbm, catboost","Real-World Example":"Click prediction, Ranking tasks","Hyperparameters to Tune":"n_estimators, learning_rate, max_depth","Speed (Training\/Prediction)":"Slow \/ Fast","Deployment Strategy":"MLflow, FastAPI","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"LogLoss, AUC","Higher or Lower":"LogLoss (Lower-is-Better), AUC (Higher-is-Better)","What It Evaluates":"Error penalization and ranking ability","Evaluation Metrics":"LogLoss(Lower-is-Better) - Confidence penalty\nAUC (Higher-is-Better) -  Class separation"},{"Type":"Supervised - Classification","Algorithm":"Naive Bayes","Best Use Case":"Probabilistic text classification","Key Fundamentals to Know":"Feature independence assumption","Libraries":"sklearn","Real-World Example":"Sentiment analysis, Document classification","Hyperparameters to Tune":"var_smoothing","Speed (Training\/Prediction)":"Fast \/ Fast","Deployment Strategy":"Pickle, Streamlit","Complexity (Low\/Med\/High)":"Low","Evaluation Metric(s)":"Accuracy, LogLoss","Higher or Lower":"Accuracy (Higher-is-Better), LogLoss (Lower-is-Better)","What It Evaluates":"Prediction confidence and correctness","Evaluation Metrics":"Accuracy (Higher-is-Better) -  Prediction match\nLogLoss(Lower-is-Better) - Probabilistic penalty"},{"Type":"Supervised - Classification","Algorithm":"MLP Classifier (Neural Network)","Best Use Case":"Learning complex non-linear patterns","Key Fundamentals to Know":"Backpropagation, Layer tuning","Libraries":"sklearn.neural_network","Real-World Example":"Digit recognition, Medical diagnosis","Hyperparameters to Tune":"hidden_layer_sizes, alpha, solver","Speed (Training\/Prediction)":"Slow \/ Fast","Deployment Strategy":"ONNX, TensorFlow Lite","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"Accuracy, Cross-Entropy","Higher or Lower":"Accuracy (Higher-is-Better), Cross-Entropy (Lower-is-Better)","What It Evaluates":"Classification and prediction confidence","Evaluation Metrics":"Accuracy (Higher-is-Better) -  Classification score\nCross-Entropy(Lower-is-Better) - Confidence-based error"},{"Type":"Supervised - Classification","Algorithm":"Quadratic Discriminant Analysis (QDA)","Best Use Case":"Gaussian-based classification with quadratic boundaries","Key Fundamentals to Know":"Covariance matrix handling, Normality assumption","Libraries":"sklearn","Real-World Example":"Iris classification, Simple biometrics","Hyperparameters to Tune":"reg_param","Speed (Training\/Prediction)":"Fast \/ Fast","Deployment Strategy":"Pickle","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Accuracy","Higher or Lower":"Accuracy (Higher-is-Better)","What It Evaluates":"Prediction quality","Evaluation Metrics":"Accuracy (Higher-is-Better) -  Percentage of correct classification"},{"Type":"Supervised - Classification","Algorithm":"Linear Discriminant Analysis (LDA)","Best Use Case":"Dimensionality reduction + classification","Key Fundamentals to Know":"Gaussian assumption, Linear boundaries","Libraries":"sklearn","Real-World Example":"Face recognition, Document classification","Hyperparameters to Tune":"solver, shrinkage","Speed (Training\/Prediction)":"Fast \/ Fast","Deployment Strategy":"Pickle","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Accuracy","Higher or Lower":"Accuracy (Higher-is-Better)","What It Evaluates":"Class separation based on projections","Evaluation Metrics":"Accuracy (Higher-is-Better) -  Classification performance"},{"Type":"Supervised - Classification","Algorithm":"Rule-Based Classifier (e.g., RIPPER)","Best Use Case":"IF-THEN rule interpretable models","Key Fundamentals to Know":"Rule induction, Pruning","Libraries":"wittgenstein, mlxtend","Real-World Example":"Credit scoring, Policy modeling","Hyperparameters to Tune":"max_rules","Speed (Training\/Prediction)":"Medium \/ Medium","Deployment Strategy":"Custom deployment","Complexity (Low\/Med\/High)":"Low","Evaluation Metric(s)":"Accuracy","Higher or Lower":"Accuracy (Higher-is-Better)","What It Evaluates":"Interpretability and rule match","Evaluation Metrics":"Accuracy (Higher-is-Better) -  Rule-based prediction score"},{"Type":"Supervised - Regression","Algorithm":"Linear Regression","Best Use Case":"Predicting continuous outcomes","Key Fundamentals to Know":"Linearity, Homoscedasticity","Libraries":"sklearn, statsmodels","Real-World Example":"House price prediction","Hyperparameters to Tune":"fit_intercept, normalize","Speed (Training\/Prediction)":"Fast \/ Fast","Deployment Strategy":"Flask, FastAPI, ONNX","Complexity (Low\/Med\/High)":"Low","Evaluation Metric(s)":"MSE, RMSE, R2","Higher or Lower":"MSE (Lower-is-Better), RMSE (Lower-is-Better), R2 (Higher-is-Better)","What It Evaluates":"Measures prediction error and model fit","Evaluation Metrics":"MSE(Lower-is-Better) - Avg squared error\nRMSE(Lower-is-Better) - Root of squared error\nR2 (Higher-is-Better) -  Explained variance"},{"Type":"Supervised - Regression","Algorithm":"Ridge Regression","Best Use Case":"Regularized linear regression","Key Fundamentals to Know":"L2 regularization","Libraries":"sklearn","Real-World Example":"Stock price modeling","Hyperparameters to Tune":"alpha, solver","Speed (Training\/Prediction)":"Fast \/ Fast","Deployment Strategy":"Flask, FastAPI, ONNX","Complexity (Low\/Med\/High)":"Low","Evaluation Metric(s)":"MSE, R2","Higher or Lower":"MSE (Lower-is-Better), R2 (Higher-is-Better)","What It Evaluates":"Improves generalization, penalizes large coefficients","Evaluation Metrics":"MSE(Lower-is-Better) - Avg error\nR2 (Higher-is-Better) -  Explained variance"},{"Type":"Supervised - Regression","Algorithm":"Lasso Regression","Best Use Case":"Sparse feature selection","Key Fundamentals to Know":"L1 regularization","Libraries":"sklearn","Real-World Example":"Feature selection in finance","Hyperparameters to Tune":"alpha","Speed (Training\/Prediction)":"Fast \/ Fast","Deployment Strategy":"Flask, FastAPI, ONNX","Complexity (Low\/Med\/High)":"Low","Evaluation Metric(s)":"MSE, R2","Higher or Lower":"MSE (Lower-is-Better), R2 (Higher-is-Better)","What It Evaluates":"Promotes sparsity, useful for feature selection","Evaluation Metrics":"MSE(Lower-is-Better) - Avg error\nR2 (Higher-is-Better) -  Explained variance"},{"Type":"Supervised - Regression","Algorithm":"ElasticNet","Best Use Case":"Hybrid regularized regression","Key Fundamentals to Know":"L1 + L2 penalty","Libraries":"sklearn","Real-World Example":"High-dimensional datasets","Hyperparameters to Tune":"alpha, l1_ratio","Speed (Training\/Prediction)":"Fast \/ Fast","Deployment Strategy":"Flask, FastAPI, ONNX","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"MSE, R2","Higher or Lower":"MSE (Lower-is-Better), R2 (Higher-is-Better)","What It Evaluates":"Balances sparsity and shrinkage","Evaluation Metrics":"MSE(Lower-is-Better) - Avg error\nR2 (Higher-is-Better) -  Explained variance"},{"Type":"Supervised - Regression","Algorithm":"Support Vector Regression (SVR)","Best Use Case":"Non-linear regression","Key Fundamentals to Know":"Kernel methods, Margin tolerance","Libraries":"sklearn","Real-World Example":"Electric load forecasting","Hyperparameters to Tune":"C, epsilon, kernel","Speed (Training\/Prediction)":"Slow \/ Medium","Deployment Strategy":"ONNX, FastAPI","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"MSE, R2","Higher or Lower":"MSE (Lower-is-Better), R2 (Higher-is-Better)","What It Evaluates":"Fits within a margin of tolerance","Evaluation Metrics":"MSE(Lower-is-Better) - Avg error\nR2 (Higher-is-Better) -  Explained variance"},{"Type":"Supervised - Regression","Algorithm":"Decision Tree Regressor","Best Use Case":"Non-linear regression with splits","Key Fundamentals to Know":"Tree-based splitting","Libraries":"sklearn","Real-World Example":"Rental price prediction","Hyperparameters to Tune":"max_depth, min_samples_split","Speed (Training\/Prediction)":"Medium \/ Fast","Deployment Strategy":"Flask, Pickle","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"MSE, MAE","Higher or Lower":"MSE (Lower-is-Better), MAE (Lower-is-Better)","What It Evaluates":"Captures non-linear patterns","Evaluation Metrics":"MSE(Lower-is-Better) - Avg squared error\nMAE(Lower-is-Better) - Avg absolute error"},{"Type":"Supervised - Regression","Algorithm":"Random Forest Regressor","Best Use Case":"Robust ensemble regressor","Key Fundamentals to Know":"Bagging, Feature randomness","Libraries":"sklearn.ensemble","Real-World Example":"Energy consumption prediction","Hyperparameters to Tune":"n_estimators, max_depth","Speed (Training\/Prediction)":"Medium \/ Fast","Deployment Strategy":"Docker, MLflow","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"MSE, R2","Higher or Lower":"MSE (Lower-is-Better), R2 (Higher-is-Better)","What It Evaluates":"Reduces overfitting, improves accuracy","Evaluation Metrics":"MSE(Lower-is-Better) - Avg error\nR2 (Higher-is-Better) -  Explained variance"},{"Type":"Supervised - Regression","Algorithm":"Gradient Boosting Regressor","Best Use Case":"Boosted tree regressor","Key Fundamentals to Know":"Sequential learning","Libraries":"xgboost, lightgbm, catboost","Real-World Example":"Customer spend prediction","Hyperparameters to Tune":"n_estimators, learning_rate","Speed (Training\/Prediction)":"Slow \/ Fast","Deployment Strategy":"MLflow, FastAPI","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"MSE, R2","Higher or Lower":"MSE (Lower-is-Better), R2 (Higher-is-Better)","What It Evaluates":"Accurate modeling via residual correction","Evaluation Metrics":"MSE(Lower-is-Better) - Avg error\nR2 (Higher-is-Better) -  Explained variance"},{"Type":"Supervised - Regression","Algorithm":"Bayesian Regression","Best Use Case":"Probabilistic linear modeling","Key Fundamentals to Know":"Prior\/posterior estimation","Libraries":"pymc3, sklearn","Real-World Example":"Uncertainty in predictions","Hyperparameters to Tune":"alpha_1, lambda_1","Speed (Training\/Prediction)":"Medium \/ Medium","Deployment Strategy":"Custom","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Log-Likelihood, R2","Higher or Lower":"Log-Likelihood (Higher-is-Better), R2 (Higher-is-Better)","What It Evaluates":"Captures parameter uncertainty","Evaluation Metrics":"Log-Likelihood (Higher-is-Better) -  Probabilistic accuracy\nR2 (Higher-is-Better) -  Explained variance"},{"Type":"Supervised - Regression","Algorithm":"KNN Regressor","Best Use Case":"Local averaging regression","Key Fundamentals to Know":"Distance metrics","Libraries":"sklearn","Real-World Example":"Geospatial interpolation","Hyperparameters to Tune":"n_neighbors, weights","Speed (Training\/Prediction)":"Slow \/ Medium","Deployment Strategy":"Pickle","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"MSE, MAE","Higher or Lower":"MSE (Lower-is-Better), MAE (Lower-is-Better)","What It Evaluates":"Predicts based on nearest neighbors","Evaluation Metrics":"MSE(Lower-is-Better) - Avg squared error\nMAE(Lower-is-Better) - Avg absolute error"},{"Type":"Supervised - Regression","Algorithm":"Quantile Regression","Best Use Case":"Predicting quantiles","Key Fundamentals to Know":"Linear modeling for quantiles","Libraries":"statsmodels, sklearn","Real-World Example":"Risk modeling","Hyperparameters to Tune":"quantile","Speed (Training\/Prediction)":"Medium \/ Fast","Deployment Strategy":"Custom","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Pinball Loss","Higher or Lower":"Pinball Loss (Lower-is-Better)","What It Evaluates":"Asymmetric loss function for quantiles","Evaluation Metrics":"Pinball Loss(Lower-is-Better) - Distance from predicted quantile"},{"Type":"Supervised - Regression","Algorithm":"Huber Regression","Best Use Case":"Robust to outliers","Key Fundamentals to Know":"Hybrid L1\/L2 loss","Libraries":"sklearn","Real-World Example":"Sensor data prediction","Hyperparameters to Tune":"epsilon","Speed (Training\/Prediction)":"Fast \/ Fast","Deployment Strategy":"Flask, FastAPI","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Huber Loss","Higher or Lower":"Huber Loss (Lower-is-Better)","What It Evaluates":"Balances squared and absolute loss","Evaluation Metrics":"Huber Loss(Lower-is-Better) - Mixed loss to handle outliers"},{"Type":"Unsupervised - Clustering","Algorithm":"K-Means","Best Use Case":"Partitioning data into clusters","Key Fundamentals to Know":"Centroid-based clustering, scaling required","Libraries":"sklearn.cluster","Real-World Example":"Customer segmentation","Hyperparameters to Tune":"n_clusters, init","Speed (Training\/Prediction)":"Fast \/ Fast","Deployment Strategy":"Pickle, Flask","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Silhouette Score, Inertia","Higher or Lower":"Silhouette (Higher-is-Better), Inertia (Lower-is-Better)","What It Evaluates":"Cluster cohesion and separation","Evaluation Metrics":"Silhouette (Higher-is-Better) -  Compactness\nInertia(Lower-is-Better) - Internal distance"},{"Type":"Unsupervised - Clustering","Algorithm":"DBSCAN","Best Use Case":"Detecting dense regions","Key Fundamentals to Know":"Density-based clustering","Libraries":"sklearn.cluster","Real-World Example":"Geospatial clustering","Hyperparameters to Tune":"eps, min_samples","Speed (Training\/Prediction)":"Medium \/ Fast","Deployment Strategy":"Rarely deployed standalone","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Cluster Purity","Higher or Lower":"Cluster Purity (Higher-is-Better)","What It Evaluates":"Accuracy of clusters vs true labels","Evaluation Metrics":"Cluster Purity (Higher-is-Better) -  Label consistency"},{"Type":"Unsupervised - Clustering","Algorithm":"Hierarchical Clustering","Best Use Case":"Hierarchical relationships","Key Fundamentals to Know":"Agglomerative clustering","Libraries":"scipy.cluster","Real-World Example":"Gene expression data","Hyperparameters to Tune":"linkage, distance_threshold","Speed (Training\/Prediction)":"Slow \/ Slow","Deployment Strategy":"Rarely deployed","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Dendrogram","Higher or Lower":"Qualitative","What It Evaluates":"Hierarchy of cluster merging","Evaluation Metrics":"Dendrogram \u201a\u00c4\u00ec Visual representation of clustering"},{"Type":"Unsupervised - Clustering","Algorithm":"Mean Shift","Best Use Case":"Mode-seeking clustering","Key Fundamentals to Know":"Bandwidth sensitive","Libraries":"sklearn.cluster","Real-World Example":"Image segmentation","Hyperparameters to Tune":"bandwidth","Speed (Training\/Prediction)":"Slow \/ Slow","Deployment Strategy":"Rarely deployed","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"Silhouette Score","Higher or Lower":"Silhouette (Higher-is-Better)","What It Evaluates":"Cluster compactness and separation","Evaluation Metrics":"Silhouette (Higher-is-Better) -  Cluster structure quality"},{"Type":"Unsupervised - Clustering","Algorithm":"Gaussian Mixture Model (GMM)","Best Use Case":"Soft probabilistic clustering","Key Fundamentals to Know":"Expectation-Maximization, Gaussian assumption","Libraries":"sklearn.mixture","Real-World Example":"Customer profiling","Hyperparameters to Tune":"n_components, covariance_type","Speed (Training\/Prediction)":"Medium \/ Medium","Deployment Strategy":"Pickle","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Log-Likelihood","Higher or Lower":"Log-Likelihood (Higher-is-Better)","What It Evaluates":"Data likelihood under mixture model","Evaluation Metrics":"Log-Likelihood (Higher-is-Better) -  Model fit to data"},{"Type":"Unsupervised - Clustering","Algorithm":"Affinity Propagation","Best Use Case":"Graph-based exemplar clustering","Key Fundamentals to Know":"Message passing between points","Libraries":"sklearn.cluster","Real-World Example":"Recommendation engines","Hyperparameters to Tune":"preference, damping","Speed (Training\/Prediction)":"Slow \/ Medium","Deployment Strategy":"Rarely deployed","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"Silhouette Score","Higher or Lower":"Silhouette (Higher-is-Better)","What It Evaluates":"Intra-cluster density","Evaluation Metrics":"Silhouette (Higher-is-Better) -  Cluster separation"},{"Type":"Unsupervised - Clustering","Algorithm":"OPTICS","Best Use Case":"Density-based clustering with ordering","Key Fundamentals to Know":"Similar to DBSCAN but sorted","Libraries":"sklearn.cluster","Real-World Example":"Fraud detection","Hyperparameters to Tune":"min_samples, xi","Speed (Training\/Prediction)":"Medium \/ Medium","Deployment Strategy":"Rarely deployed","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Reachability Plot","Higher or Lower":"Qualitative","What It Evaluates":"Cluster density visualization","Evaluation Metrics":"Reachability \u201a\u00c4\u00ec Visual cluster analysis"},{"Type":"Unsupervised - Dimensionality Reduction","Algorithm":"PCA","Best Use Case":"Reducing correlated dimensions","Key Fundamentals to Know":"Eigen decomposition","Libraries":"sklearn.decomposition","Real-World Example":"Image compression","Hyperparameters to Tune":"n_components","Speed (Training\/Prediction)":"Fast \/ Fast","Deployment Strategy":"Used in pipelines","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Explained Variance","Higher or Lower":"Explained Variance (Higher-is-Better)","What It Evaluates":"Amount of variance retained","Evaluation Metrics":"Explained Variance (Higher-is-Better) -  Data representation quality"},{"Type":"Unsupervised - Dimensionality Reduction","Algorithm":"t-SNE","Best Use Case":"2D\/3D visualization of high-dim data","Key Fundamentals to Know":"Probabilistic neighborhood embedding","Libraries":"sklearn.manifold","Real-World Example":"NLP embedding visualization","Hyperparameters to Tune":"perplexity, learning_rate","Speed (Training\/Prediction)":"Slow \/ Medium","Deployment Strategy":"Visualization only","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"Visual Clustering","Higher or Lower":"Qualitative","What It Evaluates":"Preserves local structure","Evaluation Metrics":"t-SNE \u201a\u00c4\u00ec Closeness in high-dim mapped visually"},{"Type":"Unsupervised - Dimensionality Reduction","Algorithm":"LDA (Dim Reduction)","Best Use Case":"Supervised projection","Key Fundamentals to Know":"Class separation","Libraries":"sklearn.discriminant_analysis","Real-World Example":"Face recognition","Hyperparameters to Tune":"n_components","Speed (Training\/Prediction)":"Fast \/ Fast","Deployment Strategy":"Used in classifiers","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Explained Variance","Higher or Lower":"Explained Variance (Higher-is-Better)","What It Evaluates":"Class separation in projected space","Evaluation Metrics":"Explained Variance (Higher-is-Better) -  Projection efficiency"},{"Type":"Unsupervised - Dimensionality Reduction","Algorithm":"Autoencoders","Best Use Case":"Non-linear compression","Key Fundamentals to Know":"Neural network encoder-decoder","Libraries":"keras, pytorch","Real-World Example":"Feature compression","Hyperparameters to Tune":"encoding_dim, activation","Speed (Training\/Prediction)":"Slow \/ Fast","Deployment Strategy":"TensorFlow Serving","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"Reconstruction Error","Higher or Lower":"Reconstruction Error (Lower-is-Better)","What It Evaluates":"Reconstruction-based compression quality","Evaluation Metrics":"Reconstruction Error(Lower-is-Better) - Loss from encoding"},{"Type":"Unsupervised - Dimensionality Reduction","Algorithm":"UMAP","Best Use Case":"Preserving local\/global structure","Key Fundamentals to Know":"Topological data analysis","Libraries":"umap-learn","Real-World Example":"Biological data analysis","Hyperparameters to Tune":"n_neighbors, min_dist","Speed (Training\/Prediction)":"Medium \/ Medium","Deployment Strategy":"Visualization use","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Visual Separation","Higher or Lower":"Qualitative","What It Evaluates":"Topology-preserving map","Evaluation Metrics":"UMAP \u201a\u00c4\u00ec Cluster shape & structure"},{"Type":"Unsupervised - Dimensionality Reduction","Algorithm":"ICA","Best Use Case":"Statistical independence separation","Key Fundamentals to Know":"Non-Gaussian assumption","Libraries":"sklearn.decomposition","Real-World Example":"EEG signal analysis","Hyperparameters to Tune":"n_components","Speed (Training\/Prediction)":"Fast \/ Fast","Deployment Strategy":"Used in pipelines","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Kurtosis","Higher or Lower":"Kurtosis (Higher-is-Better)","What It Evaluates":"Statistical independence of components","Evaluation Metrics":"Kurtosis (Higher-is-Better) -  Component separation"},{"Type":"Unsupervised - Dimensionality Reduction","Algorithm":"Factor Analysis","Best Use Case":"Latent factor modeling","Key Fundamentals to Know":"Common variance extraction","Libraries":"sklearn.decomposition","Real-World Example":"Psychometric modeling","Hyperparameters to Tune":"n_components","Speed (Training\/Prediction)":"Fast \/ Fast","Deployment Strategy":"Custom","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Explained Variance","Higher or Lower":"Explained Variance (Higher-is-Better)","What It Evaluates":"Latent structure representation","Evaluation Metrics":"Explained Variance (Higher-is-Better) -  Factor importance"},{"Type":"Unsupervised - Dimensionality Reduction","Algorithm":"Isomap","Best Use Case":"Preserving geodesic distances","Key Fundamentals to Know":"Manifold learning","Libraries":"sklearn.manifold","Real-World Example":"Handwritten digit reduction","Hyperparameters to Tune":"n_neighbors, n_components","Speed (Training\/Prediction)":"Medium \/ Medium","Deployment Strategy":"Visualization use","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Geodesic Distance","Higher or Lower":"Qualitative","What It Evaluates":"Manifold structure preservation","Evaluation Metrics":"Isomap \u201a\u00c4\u00ec Geodesic manifold structure"},{"Type":"Unsupervised - Anomaly Detection","Algorithm":"Isolation Forest","Best Use Case":"Outlier isolation","Key Fundamentals to Know":"Random subspace partitioning","Libraries":"sklearn.ensemble","Real-World Example":"Fraud detection","Hyperparameters to Tune":"n_estimators, contamination","Speed (Training\/Prediction)":"Fast \/ Fast","Deployment Strategy":"Flask","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Anomaly Score","Higher or Lower":"Anomaly Score (Higher-is-Better)","What It Evaluates":"Outlier probability","Evaluation Metrics":"Anomaly Score (Higher-is-Better) -  Isolation depth"},{"Type":"Unsupervised - Anomaly Detection","Algorithm":"One-Class SVM","Best Use Case":"Boundary-based anomaly detection","Key Fundamentals to Know":"Support vector hypersphere","Libraries":"sklearn.svm","Real-World Example":"Network intrusion detection","Hyperparameters to Tune":"nu, kernel","Speed (Training\/Prediction)":"Slow \/ Medium","Deployment Strategy":"Rarely deployed","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"Anomaly Score","Higher or Lower":"Anomaly Score (Higher-is-Better)","What It Evaluates":"Distance from boundary","Evaluation Metrics":"Anomaly Score (Higher-is-Better) -  Deviation severity"},{"Type":"Unsupervised - Anomaly Detection","Algorithm":"Elliptic Envelope","Best Use Case":"Robust Gaussian anomaly detection","Key Fundamentals to Know":"Elliptic covariance estimation","Libraries":"sklearn.covariance","Real-World Example":"Financial anomaly detection","Hyperparameters to Tune":"contamination, support_fraction","Speed (Training\/Prediction)":"Fast \/ Fast","Deployment Strategy":"Rarely deployed","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Mahalanobis Distance","Higher or Lower":"Distance (Lower-is-Better)","What It Evaluates":"Outlier scoring by Gaussian envelope","Evaluation Metrics":"Distance(Lower-is-Better) - Proximity to Gaussian center"},{"Type":"Unsupervised - Anomaly Detection","Algorithm":"Autoencoder-Based Anomaly Detection","Best Use Case":"Reconstruction error outliers","Key Fundamentals to Know":"Undercomplete encoder-decoder","Libraries":"keras, pytorch","Real-World Example":"IoT sensor fault detection","Hyperparameters to Tune":"encoding_dim, epochs","Speed (Training\/Prediction)":"Slow \/ Fast","Deployment Strategy":"TensorFlow Serving","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"Reconstruction Error","Higher or Lower":"Reconstruction Error (Higher-is-Better)","What It Evaluates":"Deviation from reconstruction","Evaluation Metrics":"Reconstruction Error (Higher-is-Better) -  Error = Anomaly"},{"Type":"Unsupervised - Anomaly Detection","Algorithm":"Local Outlier Factor (LOF)","Best Use Case":"Density-based anomaly detection","Key Fundamentals to Know":"Local reachability density","Libraries":"sklearn.neighbors","Real-World Example":"Credit card fraud","Hyperparameters to Tune":"n_neighbors","Speed (Training\/Prediction)":"Medium \/ Fast","Deployment Strategy":"Rarely deployed","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"LOF Score","Higher or Lower":"LOF Score (Higher-is-Better)","What It Evaluates":"Relative local density deviation","Evaluation Metrics":"LOF Score (Higher-is-Better) -  Local rarity indicator"},{"Type":"Deep Learning - Neural Network","Algorithm":"Feedforward Neural Network (FNN)","Best Use Case":"Tabular data, regression\/classification","Key Fundamentals to Know":"Fully connected layers, backpropagation","Libraries":"tensorflow, keras, pytorch","Real-World Example":"Sales forecasting","Hyperparameters to Tune":"hidden_layers, activation, optimizer","Speed (Training\/Prediction)":"Slow \/ Fast","Deployment Strategy":"TensorFlow Serving, ONNX","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"Accuracy, Cross-Entropy, MSE","Higher or Lower":"Accuracy (Higher-is-Better), Cross-Entropy (Lower-is-Better), MSE (Lower-is-Better)","What It Evaluates":"General classification or regression tasks","Evaluation Metrics":"Accuracy (Higher-is-Better) -  Prediction accuracy\nCross-Entropy(Lower-is-Better) - Class confidence loss\nMSE(Lower-is-Better) - Avg error"},{"Type":"Deep Learning - Neural Network","Algorithm":"Convolutional Neural Network (CNN)","Best Use Case":"Image data, spatial hierarchies","Key Fundamentals to Know":"Convolutions, pooling, padding","Libraries":"tensorflow, pytorch, torchvision","Real-World Example":"Medical image classification","Hyperparameters to Tune":"filters, kernel_size, strides","Speed (Training\/Prediction)":"Slow \/ Fast","Deployment Strategy":"TensorFlow Serving","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"Accuracy, IOU","Higher or Lower":"Accuracy (Higher-is-Better), IOU (Higher-is-Better)","What It Evaluates":"Image-level prediction and object overlap","Evaluation Metrics":"Accuracy (Higher-is-Better) -  Classification score\nIOU (Higher-is-Better) -  Bounding box overlap"},{"Type":"Deep Learning - Neural Network","Algorithm":"Recurrent Neural Network (RNN)","Best Use Case":"Sequential data, time series","Key Fundamentals to Know":"Temporal memory, vanishing gradients","Libraries":"tensorflow, keras, pytorch","Real-World Example":"Weather prediction","Hyperparameters to Tune":"hidden_size, sequence_length","Speed (Training\/Prediction)":"Slow \/ Medium","Deployment Strategy":"TensorFlow Serving","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"Accuracy, F1","Higher or Lower":"Accuracy (Higher-is-Better), F1 (Higher-is-Better)","What It Evaluates":"Sequence prediction quality","Evaluation Metrics":"Accuracy (Higher-is-Better) -  Match to sequence output\nF1 (Higher-is-Better) -  Precision-recall balance"},{"Type":"Deep Learning - Neural Network","Algorithm":"Long Short-Term Memory (LSTM)","Best Use Case":"Long-sequence memory modeling","Key Fundamentals to Know":"Cell state, forget gates","Libraries":"tensorflow, keras, pytorch","Real-World Example":"Speech recognition","Hyperparameters to Tune":"units, dropout","Speed (Training\/Prediction)":"Slow \/ Medium","Deployment Strategy":"TensorFlow Serving","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"Accuracy, F1","Higher or Lower":"Accuracy (Higher-is-Better), F1 (Higher-is-Better)","What It Evaluates":"Improved sequence retention","Evaluation Metrics":"Accuracy (Higher-is-Better) -  Long-term prediction accuracy\nF1 (Higher-is-Better) -  Sequential balance"},{"Type":"Deep Learning - Neural Network","Algorithm":"Gated Recurrent Unit (GRU)","Best Use Case":"Efficient sequence learning","Key Fundamentals to Know":"Gates for reset\/update","Libraries":"tensorflow, keras, pytorch","Real-World Example":"Text generation","Hyperparameters to Tune":"units, dropout","Speed (Training\/Prediction)":"Slow \/ Medium","Deployment Strategy":"TensorFlow Serving","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"Accuracy, F1","Higher or Lower":"Accuracy (Higher-is-Better), F1 (Higher-is-Better)","What It Evaluates":"Simplified LSTM performance","Evaluation Metrics":"Accuracy (Higher-is-Better) -  Seq model accuracy\nF1 (Higher-is-Better) -  Balance measure"},{"Type":"Deep Learning - Neural Network","Algorithm":"Encoder-Decoder Architecture","Best Use Case":"Seq2Seq problems","Key Fundamentals to Know":"Encoding-decoding bottleneck","Libraries":"tensorflow, pytorch","Real-World Example":"Machine translation","Hyperparameters to Tune":"encoder_units, decoder_units","Speed (Training\/Prediction)":"Slow \/ Medium","Deployment Strategy":"TensorFlow Serving","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"BLEU Score, Accuracy","Higher or Lower":"BLEU (Higher-is-Better), Accuracy (Higher-is-Better)","What It Evaluates":"Translation or sequence generation","Evaluation Metrics":"BLEU (Higher-is-Better) -  Translation quality\nAccuracy (Higher-is-Better) -  Prediction match"},{"Type":"Deep Learning - Neural Network","Algorithm":"Transformer","Best Use Case":"Long-range sequence modeling","Key Fundamentals to Know":"Attention, positional encoding","Libraries":"transformers, huggingface","Real-World Example":"Language modeling","Hyperparameters to Tune":"num_heads, layers, d_model","Speed (Training\/Prediction)":"Very Slow \/ Fast","Deployment Strategy":"ONNX, Hugging Face Hub","Complexity (Low\/Med\/High)":"Very High","Evaluation Metric(s)":"Accuracy, Perplexity","Higher or Lower":"Accuracy (Higher-is-Better), Perplexity (Lower-is-Better)","What It Evaluates":"Contextual understanding","Evaluation Metrics":"Accuracy (Higher-is-Better) -  Task accuracy\nPerplexity(Lower-is-Better) - Uncertainty"},{"Type":"Deep Learning - Neural Network","Algorithm":"ResNet","Best Use Case":"Deep convolutional learning","Key Fundamentals to Know":"Skip connections, residuals","Libraries":"tensorflow, pytorch","Real-World Example":"Image classification","Hyperparameters to Tune":"depth, block_type","Speed (Training\/Prediction)":"Slow \/ Fast","Deployment Strategy":"TensorFlow Serving","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"Accuracy, Top-1 Error","Higher or Lower":"Accuracy (Higher-is-Better), Top-1 Error (Lower-is-Better)","What It Evaluates":"Deeper networks without vanishing gradients","Evaluation Metrics":"Accuracy (Higher-is-Better) -  Correct label\nTop-1 Error(Lower-is-Better) - Misclass rate"},{"Type":"Deep Learning - Neural Network","Algorithm":"UNet","Best Use Case":"Semantic segmentation","Key Fundamentals to Know":"Contracting-expanding paths","Libraries":"tensorflow, pytorch","Real-World Example":"Medical image segmentation","Hyperparameters to Tune":"filters, depth","Speed (Training\/Prediction)":"Slow \/ Fast","Deployment Strategy":"ONNX, TorchServe","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"Dice Coefficient, IOU","Higher or Lower":"Dice (Higher-is-Better), IOU (Higher-is-Better)","What It Evaluates":"Pixel-wise prediction","Evaluation Metrics":"Dice (Higher-is-Better) -  Overlap with mask\nIOU (Higher-is-Better) -  Intersection-over-union"},{"Type":"Deep Learning - Neural Network","Algorithm":"Autoencoders (Basic, Denoising, Variational)","Best Use Case":"Compression and reconstruction","Key Fundamentals to Know":"Encoder-decoder bottleneck","Libraries":"keras, pytorch","Real-World Example":"Dimensionality reduction, anomaly detection","Hyperparameters to Tune":"encoding_dim, latent_dim","Speed (Training\/Prediction)":"Slow \/ Fast","Deployment Strategy":"TensorFlow Serving","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"Reconstruction Error","Higher or Lower":"Reconstruction Error (Lower-is-Better)","What It Evaluates":"Loss between input and reconstructed output","Evaluation Metrics":"Reconstruction Error(Lower-is-Better) - Loss due to compression"},{"Type":"Generative AI - Text & Language","Algorithm":"GPT (Generative Pretrained Transformer)","Best Use Case":"Text generation, completion","Key Fundamentals to Know":"Autoregressive transformer, pretraining","Libraries":"openai, transformers","Real-World Example":"Chatbots, writing assistants","Hyperparameters to Tune":"num_layers, max_length, temperature","Speed (Training\/Prediction)":"Slow \/ Fast","Deployment Strategy":"Hugging Face, OpenAI API","Complexity (Low\/Med\/High)":"Very High","Evaluation Metric(s)":"Perplexity, BLEU, Accuracy","Higher or Lower":"Perplexity (Lower-is-Better), BLEU (Higher-is-Better), Accuracy (Higher-is-Better)","What It Evaluates":"Language understanding and generation quality","Evaluation Metrics":"Perplexity(Lower-is-Better) - Token uncertainty\nBLEU (Higher-is-Better) -  Translation accuracy\nAccuracy (Higher-is-Better) -  Correct language predictions"},{"Type":"Generative AI - Text & Language","Algorithm":"BERT, RoBERTa, ALBERT","Best Use Case":"Contextual understanding","Key Fundamentals to Know":"Bidirectional transformer, masked LM","Libraries":"transformers, huggingface","Real-World Example":"Q&A, Sentiment Analysis","Hyperparameters to Tune":"hidden_size, attention_heads","Speed (Training\/Prediction)":"Slow \/ Fast","Deployment Strategy":"Hugging Face","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"Accuracy, F1","Higher or Lower":"Accuracy (Higher-is-Better), F1 (Higher-is-Better)","What It Evaluates":"Contextualized predictions and classification","Evaluation Metrics":"Accuracy (Higher-is-Better) -  Token\/task prediction\nF1 (Higher-is-Better) -  Precision\/recall balance"},{"Type":"Generative AI - Text & Language","Algorithm":"T5 (Text-to-Text Transfer Transformer)","Best Use Case":"Multi-task NLP","Key Fundamentals to Know":"Encoder-decoder transformer","Libraries":"transformers, huggingface","Real-World Example":"Summarization, Translation","Hyperparameters to Tune":"num_layers, d_model","Speed (Training\/Prediction)":"Slow \/ Fast","Deployment Strategy":"Hugging Face","Complexity (Low\/Med\/High)":"Very High","Evaluation Metric(s)":"BLEU, ROUGE, Accuracy","Higher or Lower":"BLEU (Higher-is-Better), ROUGE (Higher-is-Better), Accuracy (Higher-is-Better)","What It Evaluates":"Task-to-text conversion quality","Evaluation Metrics":"BLEU (Higher-is-Better) -  Translation quality\nROUGE (Higher-is-Better) -  Summary quality\nAccuracy (Higher-is-Better) -  Task fit"},{"Type":"Generative AI - Text & Language","Algorithm":"BART","Best Use Case":"Denoising autoencoder for sequence-to-sequence","Key Fundamentals to Know":"Encoder-decoder, noising","Libraries":"transformers, huggingface","Real-World Example":"Summarization, Translation","Hyperparameters to Tune":"num_layers, dropout","Speed (Training\/Prediction)":"Slow \/ Fast","Deployment Strategy":"Hugging Face","Complexity (Low\/Med\/High)":"Very High","Evaluation Metric(s)":"BLEU, ROUGE","Higher or Lower":"BLEU (Higher-is-Better), ROUGE (Higher-is-Better)","What It Evaluates":"Sequence generation quality","Evaluation Metrics":"BLEU (Higher-is-Better) -  Fluent output\nROUGE (Higher-is-Better) -  Summary overlap"},{"Type":"Generative AI - Text & Language","Algorithm":"LLaMA, Falcon, Claude","Best Use Case":"Large-scale pretraining","Key Fundamentals to Know":"Transformer architecture, instruction tuning","Libraries":"transformers, huggingface","Real-World Example":"Chat interfaces, Content generation","Hyperparameters to Tune":"num_layers, context_length","Speed (Training\/Prediction)":"Very Slow \/ Fast","Deployment Strategy":"Hugging Face, APIs","Complexity (Low\/Med\/High)":"Very High","Evaluation Metric(s)":"Accuracy, Perplexity","Higher or Lower":"Accuracy (Higher-is-Better), Perplexity (Lower-is-Better)","What It Evaluates":"Instruction-following and generation","Evaluation Metrics":"Accuracy (Higher-is-Better) -  Output alignment\nPerplexity(Lower-is-Better) - Confidence of generation"},{"Type":"Generative AI - Vision","Algorithm":"DALL\u00ac\u2211E, MidJourney, Stable Diffusion","Best Use Case":"Text-to-image generation","Key Fundamentals to Know":"Diffusion models, latent spaces","Libraries":"diffusers, stability-ai, replicate","Real-World Example":"AI Art, Image Synthesis","Hyperparameters to Tune":"guidance_scale, steps","Speed (Training\/Prediction)":"Slow \/ Medium","Deployment Strategy":"API-based, Local Inference","Complexity (Low\/Med\/High)":"Very High","Evaluation Metric(s)":"FID Score, CLIP Score","Higher or Lower":"FID (Lower-is-Better), CLIP (Higher-is-Better)","What It Evaluates":"Visual coherence and relevance","Evaluation Metrics":"FID(Lower-is-Better) - Realism\nCLIP (Higher-is-Better) -  Image-text alignment"},{"Type":"Generative AI - Vision","Algorithm":"StyleGAN, BigGAN, CycleGAN","Best Use Case":"Realistic image generation","Key Fundamentals to Know":"Adversarial training","Libraries":"tensorflow, pytorch","Real-World Example":"Face generation, Domain translation","Hyperparameters to Tune":"latent_dim, num_blocks","Speed (Training\/Prediction)":"Slow \/ Medium","Deployment Strategy":"Docker, TorchServe","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"Inception Score, FID","Higher or Lower":"Inception (Higher-is-Better), FID (Lower-is-Better)","What It Evaluates":"Visual realism and diversity","Evaluation Metrics":"Inception (Higher-is-Better) -  Diversity\nFID(Lower-is-Better) - Realism"},{"Type":"Generative AI - Vision","Algorithm":"CLIP","Best Use Case":"Vision-language understanding","Key Fundamentals to Know":"Contrastive learning","Libraries":"openai, clip-retrieval","Real-World Example":"Image search, Text-guided vision","Hyperparameters to Tune":"embedding_dim","Speed (Training\/Prediction)":"Fast \/ Fast","Deployment Strategy":"Hugging Face, API","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"Zero-Shot Accuracy","Higher or Lower":"Accuracy (Higher-is-Better)","What It Evaluates":"Cross-modal understanding","Evaluation Metrics":"Accuracy (Higher-is-Better) -  Match between text and image"},{"Type":"Generative AI - Multimodal","Algorithm":"Flamingo (DeepMind)","Best Use Case":"Visual-language fusion","Key Fundamentals to Know":"Vision encoder + causal decoder","Libraries":"deepmind, huggingface","Real-World Example":"Interactive Q&A","Hyperparameters to Tune":"num_layers, dim_head","Speed (Training\/Prediction)":"Very Slow \/ Fast","Deployment Strategy":"API, Research demo","Complexity (Low\/Med\/High)":"Very High","Evaluation Metric(s)":"Accuracy, BLEU","Higher or Lower":"Accuracy (Higher-is-Better), BLEU (Higher-is-Better)","What It Evaluates":"Multimodal understanding and response","Evaluation Metrics":"Accuracy (Higher-is-Better) -  Output match\nBLEU (Higher-is-Better) -  Text quality"},{"Type":"Generative AI - Multimodal","Algorithm":"Gato (DeepMind)","Best Use Case":"Generalist agent","Key Fundamentals to Know":"Single transformer for many modalities","Libraries":"deepmind","Real-World Example":"Control, vision, language","Hyperparameters to Tune":"context_size, transformer_layers","Speed (Training\/Prediction)":"Very Slow \/ Fast","Deployment Strategy":"Not public","Complexity (Low\/Med\/High)":"Very High","Evaluation Metric(s)":"Task Score","Higher or Lower":"Score (Higher-is-Better)","What It Evaluates":"Unified multimodal control","Evaluation Metrics":"Score (Higher-is-Better) -  General agent performance"},{"Type":"Generative AI - Multimodal","Algorithm":"Gemini, Kosmos-1","Best Use Case":"Foundation models","Key Fundamentals to Know":"Multimodal, multilingual","Libraries":"google, microsoft","Real-World Example":"Multilingual AI agents","Hyperparameters to Tune":"layers, embedding_dim","Speed (Training\/Prediction)":"Very Slow \/ Fast","Deployment Strategy":"API, Cloud-based","Complexity (Low\/Med\/High)":"Very High","Evaluation Metric(s)":"Multimodal Accuracy","Higher or Lower":"Accuracy (Higher-is-Better)","What It Evaluates":"General reasoning across inputs","Evaluation Metrics":"Accuracy (Higher-is-Better) -  Reasoning ability"},{"Type":"Reinforcement Learning - Value-Based","Algorithm":"Q-Learning","Best Use Case":"Learning state-action values","Key Fundamentals to Know":"Tabular method, Bellman equation","Libraries":"gym, numpy","Real-World Example":"Gridworld, Game AI","Hyperparameters to Tune":"learning_rate, discount_factor","Speed (Training\/Prediction)":"Medium \/ Fast","Deployment Strategy":"Custom scripts","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Cumulative Reward","Higher or Lower":"Reward (Higher-is-Better)","What It Evaluates":"Measures total rewards received","Evaluation Metrics":"Reward (Higher-is-Better) -  Long-term return"},{"Type":"Reinforcement Learning - Value-Based","Algorithm":"SARSA","Best Use Case":"On-policy learning","Key Fundamentals to Know":"Updates using current policy","Libraries":"gym, numpy","Real-World Example":"Robot navigation","Hyperparameters to Tune":"learning_rate, epsilon","Speed (Training\/Prediction)":"Medium \/ Fast","Deployment Strategy":"Custom","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Cumulative Reward","Higher or Lower":"Reward (Higher-is-Better)","What It Evaluates":"Expected future reward from current policy","Evaluation Metrics":"Reward (Higher-is-Better) -  Policy-followed performance"},{"Type":"Reinforcement Learning - Deep Value-Based","Algorithm":"Deep Q-Network (DQN)","Best Use Case":"Scalable Q-Learning","Key Fundamentals to Know":"Neural net approximator for Q-values","Libraries":"stable-baselines3, keras-rl","Real-World Example":"Atari games","Hyperparameters to Tune":"epsilon_decay, replay_buffer_size","Speed (Training\/Prediction)":"Slow \/ Medium","Deployment Strategy":"Docker, TorchServe","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"Average Episode Reward","Higher or Lower":"Reward (Higher-is-Better)","What It Evaluates":"Learned performance through gameplay","Evaluation Metrics":"Reward (Higher-is-Better) -  Better actions over time"},{"Type":"Reinforcement Learning - Policy-Based","Algorithm":"Policy Gradient Methods","Best Use Case":"Optimizing stochastic policies","Key Fundamentals to Know":"Gradient ascent on expected rewards","Libraries":"tensorflow, pytorch","Real-World Example":"Continuous control tasks","Hyperparameters to Tune":"learning_rate, entropy_coef","Speed (Training\/Prediction)":"Slow \/ Medium","Deployment Strategy":"Custom","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"Episode Return","Higher or Lower":"Return (Higher-is-Better)","What It Evaluates":"Expected return from actions","Evaluation Metrics":"Return (Higher-is-Better) -  Policy quality"},{"Type":"Reinforcement Learning - Hybrid","Algorithm":"Actor-Critic","Best Use Case":"Combines value & policy updates","Key Fundamentals to Know":"Two networks: actor & critic","Libraries":"stable-baselines3","Real-World Example":"Robotic arm control","Hyperparameters to Tune":"gamma, advantage_fn","Speed (Training\/Prediction)":"Slow \/ Medium","Deployment Strategy":"Docker, TensorFlow","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"Total Reward","Higher or Lower":"Reward (Higher-is-Better)","What It Evaluates":"Cumulative performance signal","Evaluation Metrics":"Reward (Higher-is-Better) -  Balanced learning"},{"Type":"Reinforcement Learning - Policy-Based","Algorithm":"Proximal Policy Optimization (PPO)","Best Use Case":"Stable policy updates","Key Fundamentals to Know":"Clipped objective, on-policy learning","Libraries":"stable-baselines3, ray[rllib]","Real-World Example":"Simulated environments","Hyperparameters to Tune":"clip_range, n_steps","Speed (Training\/Prediction)":"Slow \/ Medium","Deployment Strategy":"Docker, Cloud","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"Episode Return, Reward Variance","Higher or Lower":"Return (Higher-is-Better), Variance (Lower-is-Better)","What It Evaluates":"Stability and performance","Evaluation Metrics":"Return (Higher-is-Better) -  Gains\nVariance(Lower-is-Better) - Policy stability"},{"Type":"Reinforcement Learning - Policy-Based","Algorithm":"Trust Region Policy Optimization (TRPO)","Best Use Case":"Trust region for safe updates","Key Fundamentals to Know":"KL divergence constrained learning","Libraries":"rllab, garage","Real-World Example":"Simulated robotics","Hyperparameters to Tune":"max_kl, cg_iters","Speed (Training\/Prediction)":"Slow \/ Medium","Deployment Strategy":"Custom","Complexity (Low\/Med\/High)":"Very High","Evaluation Metric(s)":"Average Reward","Higher or Lower":"Reward (Higher-is-Better)","What It Evaluates":"Safeguarded learning updates","Evaluation Metrics":"Reward (Higher-is-Better) -  Effective exploration"},{"Type":"Reinforcement Learning - Hybrid","Algorithm":"Advantage Actor Critic (A2C, A3C)","Best Use Case":"Parallelized actor-critic","Key Fundamentals to Know":"Shared model for multiple environments","Libraries":"baselines, torch-ac","Real-World Example":"OpenAI gym tasks","Hyperparameters to Tune":"value_loss_coef, entropy_coef","Speed (Training\/Prediction)":"Slow \/ Medium","Deployment Strategy":"Custom \/ Distributed","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"Total Return","Higher or Lower":"Return (Higher-is-Better)","What It Evaluates":"Faster & distributed learning","Evaluation Metrics":"Return (Higher-is-Better) -  Converged training efficiency"},{"Type":"Reinforcement Learning - Model-Free","Algorithm":"Monte Carlo Methods","Best Use Case":"Learning via episodic return","Key Fundamentals to Know":"Delayed reward assignment","Libraries":"gym, custom","Real-World Example":"Small MDPs","Hyperparameters to Tune":"episode_length, discount","Speed (Training\/Prediction)":"Fast \/ Medium","Deployment Strategy":"Scripts","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Average Return","Higher or Lower":"Return (Higher-is-Better)","What It Evaluates":"Accuracy of return estimates","Evaluation Metrics":"Return (Higher-is-Better) -  Learning from full episodes"},{"Type":"Reinforcement Learning - Temporal Difference","Algorithm":"TD-Learning (TD(0), TD(\u0152\u00aa))","Best Use Case":"Bootstrapped return prediction","Key Fundamentals to Know":"Combines Monte Carlo & Bellman","Libraries":"gym, numpy","Real-World Example":"Simple MDPs","Hyperparameters to Tune":"lambda, alpha","Speed (Training\/Prediction)":"Fast \/ Fast","Deployment Strategy":"Local","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Mean TD Error","Higher or Lower":"TD Error (Lower-is-Better)","What It Evaluates":"Error in expected returns","Evaluation Metrics":"TD Error(Lower-is-Better) - Estimate refinement"},{"Type":"Graph ML","Algorithm":"Graph Neural Networks (GNN)","Best Use Case":"Node classification, link prediction","Key Fundamentals to Know":"Message passing, neighborhood aggregation","Libraries":"dgl, pytorch-geometric","Real-World Example":"Social network analysis","Hyperparameters to Tune":"num_layers, hidden_dim","Speed (Training\/Prediction)":"Slow \/ Medium","Deployment Strategy":"TorchServe, Docker","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"Accuracy, F1","Higher or Lower":"Accuracy (Higher-is-Better), F1 (Higher-is-Better)","What It Evaluates":"Node-wise prediction performance","Evaluation Metrics":"Accuracy (Higher-is-Better) -  Node label match\nF1 (Higher-is-Better) -  Balanced metric"},{"Type":"Graph ML","Algorithm":"Graph Convolutional Networks (GCN)","Best Use Case":"Graph-structured learning","Key Fundamentals to Know":"Spectral convolutions on graphs","Libraries":"dgl, pytorch-geometric","Real-World Example":"Citation networks","Hyperparameters to Tune":"hidden_units, dropout","Speed (Training\/Prediction)":"Slow \/ Medium","Deployment Strategy":"TorchServe","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"Accuracy","Higher or Lower":"Accuracy (Higher-is-Better)","What It Evaluates":"Node classification correctness","Evaluation Metrics":"Accuracy (Higher-is-Better) -  Label prediction match"},{"Type":"Graph ML","Algorithm":"Graph Attention Networks (GAT)","Best Use Case":"Attention over neighbors","Key Fundamentals to Know":"Self-attention on graph nodes","Libraries":"dgl, pytorch-geometric","Real-World Example":"Knowledge graphs","Hyperparameters to Tune":"num_heads, dropout","Speed (Training\/Prediction)":"Slow \/ Medium","Deployment Strategy":"Docker, TorchServe","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"Accuracy, F1","Higher or Lower":"Accuracy (Higher-is-Better), F1 (Higher-is-Better)","What It Evaluates":"Context-aware prediction quality","Evaluation Metrics":"Accuracy (Higher-is-Better) -  Correct classification\nF1 (Higher-is-Better) -  Performance measure"},{"Type":"Graph ML","Algorithm":"Graph Autoencoders","Best Use Case":"Graph embedding, reconstruction","Key Fundamentals to Know":"Encoder-decoder on graphs","Libraries":"pytorch-geometric","Real-World Example":"Graph compression, link prediction","Hyperparameters to Tune":"embedding_dim, learning_rate","Speed (Training\/Prediction)":"Medium \/ Fast","Deployment Strategy":"Custom","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Reconstruction Error","Higher or Lower":"Error (Lower-is-Better)","What It Evaluates":"How well the graph is encoded","Evaluation Metrics":"Error(Lower-is-Better) - Embedding quality"},{"Type":"Graph ML","Algorithm":"DeepWalk","Best Use Case":"Unsupervised node embedding","Key Fundamentals to Know":"Random walks + Word2Vec","Libraries":"stellargraph, gensim","Real-World Example":"Community detection","Hyperparameters to Tune":"walk_length, window_size","Speed (Training\/Prediction)":"Fast \/ Fast","Deployment Strategy":"Custom pipeline","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Embedding Similarity","Higher or Lower":"Similarity (Higher-is-Better)","What It Evaluates":"Closeness in embedding space","Evaluation Metrics":"Similarity (Higher-is-Better) -  Proximity in learned space"},{"Type":"Graph ML","Algorithm":"Node2Vec \/ Edge2Vec","Best Use Case":"Biased random walks for embedding","Key Fundamentals to Know":"Flexible walk sampling strategy","Libraries":"stellargraph, nodevectors","Real-World Example":"Graph recommendation","Hyperparameters to Tune":"p, q, dimensions","Speed (Training\/Prediction)":"Fast \/ Fast","Deployment Strategy":"Flask, Custom","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Link Prediction Accuracy","Higher or Lower":"Accuracy (Higher-is-Better)","What It Evaluates":"Link prediction via embeddings","Evaluation Metrics":"Accuracy (Higher-is-Better) -  True edge prediction"},{"Type":"Graph ML","Algorithm":"Knowledge Graph Embeddings (TransE, TransR)","Best Use Case":"Triple representation in low-dim space","Key Fundamentals to Know":"Translation-based embedding","Libraries":"ampligraph, openKE","Real-World Example":"Knowledge base completion","Hyperparameters to Tune":"embedding_dim, margin","Speed (Training\/Prediction)":"Medium \/ Medium","Deployment Strategy":"API, Custom","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"MRR, Hits@K","Higher or Lower":"MRR (Higher-is-Better), Hits@K (Higher-is-Better)","What It Evaluates":"Entity and relation prediction","Evaluation Metrics":"MRR (Higher-is-Better) -  Rank avg.\nHits@K (Higher-is-Better) -  Top-K inclusion"},{"Type":"Probabilistic \/ Bayesian","Algorithm":"Bayesian Networks","Best Use Case":"Probabilistic reasoning","Key Fundamentals to Know":"Directed acyclic graphs, conditional probabilities","Libraries":"pgmpy, pomegranate","Real-World Example":"Medical diagnosis, Fraud detection","Hyperparameters to Tune":"structure_type, prior_type","Speed (Training\/Prediction)":"Medium \/ Medium","Deployment Strategy":"Custom, Flask","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Log-Likelihood, Accuracy","Higher or Lower":"Log-Likelihood (Higher-is-Better), Accuracy (Higher-is-Better)","What It Evaluates":"Joint probability modeling","Evaluation Metrics":"Log-Likelihood (Higher-is-Better) -  Model fit\nAccuracy (Higher-is-Better) -  Prediction performance"},{"Type":"Probabilistic \/ Bayesian","Algorithm":"Hidden Markov Models (HMM)","Best Use Case":"Sequential probabilistic modeling","Key Fundamentals to Know":"State transition + emission probabilities","Libraries":"hmmlearn, pomegranate","Real-World Example":"Speech recognition, POS tagging","Hyperparameters to Tune":"n_components, covariance_type","Speed (Training\/Prediction)":"Medium \/ Medium","Deployment Strategy":"Flask, Pickle","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Log-Likelihood","Higher or Lower":"Log-Likelihood (Higher-is-Better)","What It Evaluates":"Likelihood of observed sequences","Evaluation Metrics":"Log-Likelihood (Higher-is-Better) -  Sequence plausibility"},{"Type":"Probabilistic \/ Bayesian","Algorithm":"Markov Decision Processes (MDP)","Best Use Case":"Planning with decision uncertainty","Key Fundamentals to Know":"States, actions, rewards, transitions","Libraries":"pymdptoolbox","Real-World Example":"Robot path planning","Hyperparameters to Tune":"gamma, policy_eval_method","Speed (Training\/Prediction)":"Medium \/ Medium","Deployment Strategy":"Custom","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Cumulative Reward","Higher or Lower":"Reward (Higher-is-Better)","What It Evaluates":"Expected return with policy","Evaluation Metrics":"Reward (Higher-is-Better) -  Optimal policy evaluation"},{"Type":"Probabilistic \/ Bayesian","Algorithm":"Gaussian Processes (GP)","Best Use Case":"Non-parametric regression\/classification","Key Fundamentals to Know":"Bayesian inference over functions","Libraries":"GPy, scikit-learn","Real-World Example":"Time-series prediction","Hyperparameters to Tune":"kernel, alpha","Speed (Training\/Prediction)":"Slow \/ Medium","Deployment Strategy":"ONNX, Flask","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"Log-Marginal Likelihood, RMSE","Higher or Lower":"Likelihood (Higher-is-Better), RMSE (Lower-is-Better)","What It Evaluates":"Uncertainty-aware predictions","Evaluation Metrics":"Log-Marginal Likelihood (Higher-is-Better) -  Fit\nRMSE(Lower-is-Better) - Prediction error"},{"Type":"Probabilistic \/ Bayesian","Algorithm":"Probabilistic Graphical Models","Best Use Case":"Flexible probabilistic inference","Key Fundamentals to Know":"Graph-based probability distributions","Libraries":"pgmpy, pyro","Real-World Example":"Causal inference","Hyperparameters to Tune":"graph_structure, inference_method","Speed (Training\/Prediction)":"Medium \/ Medium","Deployment Strategy":"Custom","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"Log-Likelihood, Accuracy","Higher or Lower":"Log-Likelihood (Higher-is-Better), Accuracy (Higher-is-Better)","What It Evaluates":"Joint inference over variables","Evaluation Metrics":"Log-Likelihood (Higher-is-Better) -  Data fit\nAccuracy (Higher-is-Better) -  Output confidence"},{"Type":"Ensemble","Algorithm":"Bagging (e.g., Random Forest)","Best Use Case":"Reduce variance through averaging","Key Fundamentals to Know":"Bootstrap sampling, parallel trees","Libraries":"sklearn.ensemble","Real-World Example":"Credit scoring, Churn prediction","Hyperparameters to Tune":"n_estimators, max_features","Speed (Training\/Prediction)":"Medium \/ Fast","Deployment Strategy":"Flask, Docker","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Accuracy, AUC","Higher or Lower":"Accuracy (Higher-is-Better), AUC (Higher-is-Better)","What It Evaluates":"Improved stability and reduced overfitting","Evaluation Metrics":"Accuracy (Higher-is-Better) -  Majority vote accuracy\nAUC (Higher-is-Better) -  Class separability"},{"Type":"Ensemble","Algorithm":"Boosting (e.g., AdaBoost, XGBoost)","Best Use Case":"Reduce bias through sequential correction","Key Fundamentals to Know":"Weighted voting, Residual fitting","Libraries":"xgboost, lightgbm, catboost","Real-World Example":"Fraud detection, Click prediction","Hyperparameters to Tune":"learning_rate, n_estimators","Speed (Training\/Prediction)":"Slow \/ Fast","Deployment Strategy":"MLflow, Docker","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"Accuracy, LogLoss, AUC","Higher or Lower":"Accuracy (Higher-is-Better), LogLoss (Lower-is-Better), AUC (Higher-is-Better)","What It Evaluates":"Accurate and interpretable boosting","Evaluation Metrics":"Accuracy (Higher-is-Better) -  Overall prediction\nLogLoss(Lower-is-Better) - Confidence calibration\nAUC (Higher-is-Better) -  ROC performance"},{"Type":"Ensemble","Algorithm":"Stacking (Stacked Generalization)","Best Use Case":"Meta-model learning over base learners","Key Fundamentals to Know":"Blend diverse models using a meta-learner","Libraries":"sklearn.ensemble, mlxtend","Real-World Example":"Complex tabular data","Hyperparameters to Tune":"base_models, final_estimator","Speed (Training\/Prediction)":"Slow \/ Medium","Deployment Strategy":"Custom, Docker","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"Accuracy, AUC","Higher or Lower":"Accuracy (Higher-is-Better), AUC (Higher-is-Better)","What It Evaluates":"Combines strengths of multiple models","Evaluation Metrics":"Accuracy (Higher-is-Better) -  Combined model accuracy\nAUC (Higher-is-Better) -  Aggregate separability"},{"Type":"Ensemble","Algorithm":"Voting Classifier\/Regressor","Best Use Case":"Majority (classification) \/ Mean (regression)","Key Fundamentals to Know":"Hard or soft voting over models","Libraries":"sklearn.ensemble","Real-World Example":"General purpose ensembling","Hyperparameters to Tune":"voting, weights","Speed (Training\/Prediction)":"Fast \/ Fast","Deployment Strategy":"Flask, Pickle","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Accuracy, R2","Higher or Lower":"Accuracy (Higher-is-Better), R2 (Higher-is-Better)","What It Evaluates":"Simple model averaging","Evaluation Metrics":"Accuracy (Higher-is-Better) -  Voting correctness\nR2 (Higher-is-Better) -  Explained variance"},{"Type":"Ensemble","Algorithm":"Blending","Best Use Case":"Holdout blending of predictions","Key Fundamentals to Know":"Validation set-based meta-learner","Libraries":"mlxtend, custom code","Real-World Example":"Competitions, Kaggle","Hyperparameters to Tune":"blend_ratio, holdout_split","Speed (Training\/Prediction)":"Medium \/ Medium","Deployment Strategy":"Custom","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Accuracy, AUC","Higher or Lower":"Accuracy (Higher-is-Better), AUC (Higher-is-Better)","What It Evaluates":"Heuristic model stacking","Evaluation Metrics":"Accuracy (Higher-is-Better) -  Final prediction quality\nAUC (Higher-is-Better) -  Class separability"},{"Type":"Explainability Techniques","Algorithm":"SHAP","Best Use Case":"Global + local feature attribution","Key Fundamentals to Know":"Game theory, model-agnostic","Libraries":"shap","Real-World Example":"Finance, healthcare","Hyperparameters to Tune":"explainer_type, background_data","Speed (Training\/Prediction)":"Medium \/ Medium","Deployment Strategy":"Streamlit, Jupyter","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"SHAP Value Magnitude","Higher or Lower":"Magnitude(Higher-is-Better)","What It Evaluates":"Contribution of features to prediction","Evaluation Metrics":"SHAP (Higher-is-Better) - Impact of each feature on prediction"},{"Type":"Explainability Techniques","Algorithm":"LIME","Best Use Case":"Local surrogate explanations","Key Fundamentals to Know":"Linear approximation around prediction","Libraries":"lime","Real-World Example":"Model debugging, Trust building","Hyperparameters to Tune":"kernel_width, num_features","Speed (Training\/Prediction)":"Medium \/ Medium","Deployment Strategy":"Not production-ready","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"Feature Weights","Higher or Lower":"Magnitude(Higher-is-Better)","What It Evaluates":"Feature influence on specific prediction","Evaluation Metrics":"LIME (Higher-is-Better) - Local feature importance"},{"Type":"Explainability Techniques","Algorithm":"Integrated Gradients","Best Use Case":"Attribution in neural networks","Key Fundamentals to Know":"Path integral of gradients","Libraries":"captum, tensorflow","Real-World Example":"Vision, NLP","Hyperparameters to Tune":"steps, baseline","Speed (Training\/Prediction)":"Slow \/ Medium","Deployment Strategy":"TensorBoard, Captum","Complexity (Low\/Med\/High)":"High","Evaluation Metric(s)":"Attribution Score","Higher or Lower":"Magnitude(Higher-is-Better)","What It Evaluates":"Importance of input features","Evaluation Metrics":"Attribution (Higher-is-Better) - Influence of input on output"},{"Type":"Explainability Techniques","Algorithm":"Permutation Importance","Best Use Case":"Global importance measure","Key Fundamentals to Know":"Randomly permute each feature","Libraries":"sklearn.inspection","Real-World Example":"Any tabular model","Hyperparameters to Tune":"n_repeats","Speed (Training\/Prediction)":"Fast \/ Fast","Deployment Strategy":"Jupyter, Streamlit","Complexity (Low\/Med\/High)":"Low","Evaluation Metric(s)":"Importance Score","Higher or Lower":"Score(Higher-is-Better)","What It Evaluates":"Effect of shuffling features on accuracy","Evaluation Metrics":"Importance Score (Higher-is-Better) - Impact of permuted features"},{"Type":"Explainability Techniques","Algorithm":"PDP","Best Use Case":"Visualizing feature impact","Key Fundamentals to Know":"Marginal effect of features","Libraries":"sklearn.inspection","Real-World Example":"Tabular feature analysis","Hyperparameters to Tune":"grid_resolution","Speed (Training\/Prediction)":"Fast \/ Medium","Deployment Strategy":"Streamlit, Jupyter","Complexity (Low\/Med\/High)":"Medium","Evaluation Metric(s)":"PDP Curve","Higher or Lower":"Qualitative","What It Evaluates":"Effect of one or two features on prediction","Evaluation Metrics":"PDP - Response surface visualization"}]