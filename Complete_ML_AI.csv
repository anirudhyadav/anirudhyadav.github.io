Type,Algorithm,Best Use Case,Key Fundamentals to Know,Libraries,Real-World Example,Hyperparameters to Tune,Speed (Training/Prediction),Deployment Strategy,Complexity (Low/Med/High),Evaluation Metric(s),Higher or Lower,What It Evaluates,Evaluation Metrics
Supervised - Classification,Logistic Regression,"Binary classification, baseline model","Feature scaling, Linear relationship assumption","sklearn, statsmodels","Spam detection, Credit scoring","C, penalty, solver",Fast / Fast,"Flask, FastAPI, ONNX",Low,"Accuracy, AUC, F1","Accuracy (Higher-is-Better), AUC (Higher-is-Better), F1 (Higher-is-Better)",Evaluates classification correctness and separability,"Accuracy (Higher-is-Better) -  Correct predictions
AUC (Higher-is-Better) -  Separability
F1 (Higher-is-Better) -  Harmonic mean of precision and recall"
Supervised - Classification,K-Nearest Neighbors (KNN),Pattern recognition with few samples,"Distance metrics, Scaling required",sklearn,"Recommendation systems, Handwriting recognition","n_neighbors, weights",Slow / Medium,"Pickle, Streamlit",Medium,"Accuracy, Confusion Matrix",Accuracy (Higher-is-Better),Prediction correctness and error breakdown,"Accuracy (Higher-is-Better) -  Correctness
Confusion Matrix - TP, FP, TN, FN analysis"
Supervised - Classification,Support Vector Machine (SVM),High-dimensional data classification,"Kernel trick, Hyperplane separation",sklearn,"Text classification, Image recognition","C, kernel, gamma",Slow / Medium,"ONNX, FastAPI",High,"Accuracy, ROC AUC","Accuracy (Higher-is-Better), ROC AUC (Higher-is-Better)",Class separability and accuracy,"Accuracy (Higher-is-Better) -  Correctness
ROC AUC (Higher-is-Better) -  Threshold-independent separation"
Supervised - Classification,Decision Tree Classifier,Interpretable rule-based model,"Overfitting control, Feature importance",sklearn,"Loan approval, Customer churn","max_depth, min_samples_split",Medium / Fast,"Flask, Pickle",Medium,"Accuracy, Gini","Accuracy (Higher-is-Better), Gini (Lower-is-Better)",Correct predictions and split impurity,"Accuracy (Higher-is-Better) -  Correct classification
Gini(Lower-is-Better) - Split quality"
Supervised - Classification,Random Forest Classifier,Robust ensemble of trees,"Bagging, Feature randomness",sklearn.ensemble,"Fraud detection, Disease diagnosis","n_estimators, max_depth, max_features",Medium / Fast,"Docker, MLflow",Medium,"Accuracy, AUC","Accuracy (Higher-is-Better), AUC (Higher-is-Better)",Improved stability and performance,"Accuracy (Higher-is-Better) -  Overall correctness
AUC (Higher-is-Better) -  Separability measure"
Supervised - Classification,Gradient Boosting Classifier,Boosted trees for improved accuracy,"Sequential learning, Learning rate tuning","xgboost, lightgbm, catboost","Click prediction, Ranking tasks","n_estimators, learning_rate, max_depth",Slow / Fast,"MLflow, FastAPI",High,"LogLoss, AUC","LogLoss (Lower-is-Better), AUC (Higher-is-Better)",Error penalization and ranking ability,"LogLoss(Lower-is-Better) - Confidence penalty
AUC (Higher-is-Better) -  Class separation"
Supervised - Classification,Naive Bayes,Probabilistic text classification,Feature independence assumption,sklearn,"Sentiment analysis, Document classification",var_smoothing,Fast / Fast,"Pickle, Streamlit",Low,"Accuracy, LogLoss","Accuracy (Higher-is-Better), LogLoss (Lower-is-Better)",Prediction confidence and correctness,"Accuracy (Higher-is-Better) -  Prediction match
LogLoss(Lower-is-Better) - Probabilistic penalty"
Supervised - Classification,MLP Classifier (Neural Network),Learning complex non-linear patterns,"Backpropagation, Layer tuning",sklearn.neural_network,"Digit recognition, Medical diagnosis","hidden_layer_sizes, alpha, solver",Slow / Fast,"ONNX, TensorFlow Lite",High,"Accuracy, Cross-Entropy","Accuracy (Higher-is-Better), Cross-Entropy (Lower-is-Better)",Classification and prediction confidence,"Accuracy (Higher-is-Better) -  Classification score
Cross-Entropy(Lower-is-Better) - Confidence-based error"
Supervised - Classification,Quadratic Discriminant Analysis (QDA),Gaussian-based classification with quadratic boundaries,"Covariance matrix handling, Normality assumption",sklearn,"Iris classification, Simple biometrics",reg_param,Fast / Fast,Pickle,Medium,Accuracy,Accuracy (Higher-is-Better),Prediction quality,Accuracy (Higher-is-Better) -  Percentage of correct classification
Supervised - Classification,Linear Discriminant Analysis (LDA),Dimensionality reduction + classification,"Gaussian assumption, Linear boundaries",sklearn,"Face recognition, Document classification","solver, shrinkage",Fast / Fast,Pickle,Medium,Accuracy,Accuracy (Higher-is-Better),Class separation based on projections,Accuracy (Higher-is-Better) -  Classification performance
Supervised - Classification,"Rule-Based Classifier (e.g., RIPPER)",IF-THEN rule interpretable models,"Rule induction, Pruning","wittgenstein, mlxtend","Credit scoring, Policy modeling",max_rules,Medium / Medium,Custom deployment,Low,Accuracy,Accuracy (Higher-is-Better),Interpretability and rule match,Accuracy (Higher-is-Better) -  Rule-based prediction score
Supervised - Regression,Linear Regression,Predicting continuous outcomes,"Linearity, Homoscedasticity","sklearn, statsmodels",House price prediction,"fit_intercept, normalize",Fast / Fast,"Flask, FastAPI, ONNX",Low,"MSE, RMSE, R2","MSE (Lower-is-Better), RMSE (Lower-is-Better), R2 (Higher-is-Better)",Measures prediction error and model fit,"MSE(Lower-is-Better) - Avg squared error
RMSE(Lower-is-Better) - Root of squared error
R2 (Higher-is-Better) -  Explained variance"
Supervised - Regression,Ridge Regression,Regularized linear regression,L2 regularization,sklearn,Stock price modeling,"alpha, solver",Fast / Fast,"Flask, FastAPI, ONNX",Low,"MSE, R2","MSE (Lower-is-Better), R2 (Higher-is-Better)","Improves generalization, penalizes large coefficients","MSE(Lower-is-Better) - Avg error
R2 (Higher-is-Better) -  Explained variance"
Supervised - Regression,Lasso Regression,Sparse feature selection,L1 regularization,sklearn,Feature selection in finance,alpha,Fast / Fast,"Flask, FastAPI, ONNX",Low,"MSE, R2","MSE (Lower-is-Better), R2 (Higher-is-Better)","Promotes sparsity, useful for feature selection","MSE(Lower-is-Better) - Avg error
R2 (Higher-is-Better) -  Explained variance"
Supervised - Regression,ElasticNet,Hybrid regularized regression,L1 + L2 penalty,sklearn,High-dimensional datasets,"alpha, l1_ratio",Fast / Fast,"Flask, FastAPI, ONNX",Medium,"MSE, R2","MSE (Lower-is-Better), R2 (Higher-is-Better)",Balances sparsity and shrinkage,"MSE(Lower-is-Better) - Avg error
R2 (Higher-is-Better) -  Explained variance"
Supervised - Regression,Support Vector Regression (SVR),Non-linear regression,"Kernel methods, Margin tolerance",sklearn,Electric load forecasting,"C, epsilon, kernel",Slow / Medium,"ONNX, FastAPI",High,"MSE, R2","MSE (Lower-is-Better), R2 (Higher-is-Better)",Fits within a margin of tolerance,"MSE(Lower-is-Better) - Avg error
R2 (Higher-is-Better) -  Explained variance"
Supervised - Regression,Decision Tree Regressor,Non-linear regression with splits,Tree-based splitting,sklearn,Rental price prediction,"max_depth, min_samples_split",Medium / Fast,"Flask, Pickle",Medium,"MSE, MAE","MSE (Lower-is-Better), MAE (Lower-is-Better)",Captures non-linear patterns,"MSE(Lower-is-Better) - Avg squared error
MAE(Lower-is-Better) - Avg absolute error"
Supervised - Regression,Random Forest Regressor,Robust ensemble regressor,"Bagging, Feature randomness",sklearn.ensemble,Energy consumption prediction,"n_estimators, max_depth",Medium / Fast,"Docker, MLflow",Medium,"MSE, R2","MSE (Lower-is-Better), R2 (Higher-is-Better)","Reduces overfitting, improves accuracy","MSE(Lower-is-Better) - Avg error
R2 (Higher-is-Better) -  Explained variance"
Supervised - Regression,Gradient Boosting Regressor,Boosted tree regressor,Sequential learning,"xgboost, lightgbm, catboost",Customer spend prediction,"n_estimators, learning_rate",Slow / Fast,"MLflow, FastAPI",High,"MSE, R2","MSE (Lower-is-Better), R2 (Higher-is-Better)",Accurate modeling via residual correction,"MSE(Lower-is-Better) - Avg error
R2 (Higher-is-Better) -  Explained variance"
Supervised - Regression,Bayesian Regression,Probabilistic linear modeling,Prior/posterior estimation,"pymc3, sklearn",Uncertainty in predictions,"alpha_1, lambda_1",Medium / Medium,Custom,Medium,"Log-Likelihood, R2","Log-Likelihood (Higher-is-Better), R2 (Higher-is-Better)",Captures parameter uncertainty,"Log-Likelihood (Higher-is-Better) -  Probabilistic accuracy
R2 (Higher-is-Better) -  Explained variance"
Supervised - Regression,KNN Regressor,Local averaging regression,Distance metrics,sklearn,Geospatial interpolation,"n_neighbors, weights",Slow / Medium,Pickle,Medium,"MSE, MAE","MSE (Lower-is-Better), MAE (Lower-is-Better)",Predicts based on nearest neighbors,"MSE(Lower-is-Better) - Avg squared error
MAE(Lower-is-Better) - Avg absolute error"
Supervised - Regression,Quantile Regression,Predicting quantiles,Linear modeling for quantiles,"statsmodels, sklearn",Risk modeling,quantile,Medium / Fast,Custom,Medium,Pinball Loss,Pinball Loss (Lower-is-Better),Asymmetric loss function for quantiles,Pinball Loss(Lower-is-Better) - Distance from predicted quantile
Supervised - Regression,Huber Regression,Robust to outliers,Hybrid L1/L2 loss,sklearn,Sensor data prediction,epsilon,Fast / Fast,"Flask, FastAPI",Medium,Huber Loss,Huber Loss (Lower-is-Better),Balances squared and absolute loss,Huber Loss(Lower-is-Better) - Mixed loss to handle outliers
Unsupervised - Clustering,K-Means,Partitioning data into clusters,"Centroid-based clustering, scaling required",sklearn.cluster,Customer segmentation,"n_clusters, init",Fast / Fast,"Pickle, Flask",Medium,"Silhouette Score, Inertia","Silhouette (Higher-is-Better), Inertia (Lower-is-Better)",Cluster cohesion and separation,"Silhouette (Higher-is-Better) -  Compactness
Inertia(Lower-is-Better) - Internal distance"
Unsupervised - Clustering,DBSCAN,Detecting dense regions,Density-based clustering,sklearn.cluster,Geospatial clustering,"eps, min_samples",Medium / Fast,Rarely deployed standalone,Medium,Cluster Purity,Cluster Purity (Higher-is-Better),Accuracy of clusters vs true labels,Cluster Purity (Higher-is-Better) -  Label consistency
Unsupervised - Clustering,Hierarchical Clustering,Hierarchical relationships,Agglomerative clustering,scipy.cluster,Gene expression data,"linkage, distance_threshold",Slow / Slow,Rarely deployed,Medium,Dendrogram,Qualitative,Hierarchy of cluster merging,Dendrogram ‚Äì Visual representation of clustering
Unsupervised - Clustering,Mean Shift,Mode-seeking clustering,Bandwidth sensitive,sklearn.cluster,Image segmentation,bandwidth,Slow / Slow,Rarely deployed,High,Silhouette Score,Silhouette (Higher-is-Better),Cluster compactness and separation,Silhouette (Higher-is-Better) -  Cluster structure quality
Unsupervised - Clustering,Gaussian Mixture Model (GMM),Soft probabilistic clustering,"Expectation-Maximization, Gaussian assumption",sklearn.mixture,Customer profiling,"n_components, covariance_type",Medium / Medium,Pickle,Medium,Log-Likelihood,Log-Likelihood (Higher-is-Better),Data likelihood under mixture model,Log-Likelihood (Higher-is-Better) -  Model fit to data
Unsupervised - Clustering,Affinity Propagation,Graph-based exemplar clustering,Message passing between points,sklearn.cluster,Recommendation engines,"preference, damping",Slow / Medium,Rarely deployed,High,Silhouette Score,Silhouette (Higher-is-Better),Intra-cluster density,Silhouette (Higher-is-Better) -  Cluster separation
Unsupervised - Clustering,OPTICS,Density-based clustering with ordering,Similar to DBSCAN but sorted,sklearn.cluster,Fraud detection,"min_samples, xi",Medium / Medium,Rarely deployed,Medium,Reachability Plot,Qualitative,Cluster density visualization,Reachability ‚Äì Visual cluster analysis
Unsupervised - Dimensionality Reduction,PCA,Reducing correlated dimensions,Eigen decomposition,sklearn.decomposition,Image compression,n_components,Fast / Fast,Used in pipelines,Medium,Explained Variance,Explained Variance (Higher-is-Better),Amount of variance retained,Explained Variance (Higher-is-Better) -  Data representation quality
Unsupervised - Dimensionality Reduction,t-SNE,2D/3D visualization of high-dim data,Probabilistic neighborhood embedding,sklearn.manifold,NLP embedding visualization,"perplexity, learning_rate",Slow / Medium,Visualization only,High,Visual Clustering,Qualitative,Preserves local structure,t-SNE ‚Äì Closeness in high-dim mapped visually
Unsupervised - Dimensionality Reduction,LDA (Dim Reduction),Supervised projection,Class separation,sklearn.discriminant_analysis,Face recognition,n_components,Fast / Fast,Used in classifiers,Medium,Explained Variance,Explained Variance (Higher-is-Better),Class separation in projected space,Explained Variance (Higher-is-Better) -  Projection efficiency
Unsupervised - Dimensionality Reduction,Autoencoders,Non-linear compression,Neural network encoder-decoder,"keras, pytorch",Feature compression,"encoding_dim, activation",Slow / Fast,TensorFlow Serving,High,Reconstruction Error,Reconstruction Error (Lower-is-Better),Reconstruction-based compression quality,Reconstruction Error(Lower-is-Better) - Loss from encoding
Unsupervised - Dimensionality Reduction,UMAP,Preserving local/global structure,Topological data analysis,umap-learn,Biological data analysis,"n_neighbors, min_dist",Medium / Medium,Visualization use,Medium,Visual Separation,Qualitative,Topology-preserving map,UMAP ‚Äì Cluster shape & structure
Unsupervised - Dimensionality Reduction,ICA,Statistical independence separation,Non-Gaussian assumption,sklearn.decomposition,EEG signal analysis,n_components,Fast / Fast,Used in pipelines,Medium,Kurtosis,Kurtosis (Higher-is-Better),Statistical independence of components,Kurtosis (Higher-is-Better) -  Component separation
Unsupervised - Dimensionality Reduction,Factor Analysis,Latent factor modeling,Common variance extraction,sklearn.decomposition,Psychometric modeling,n_components,Fast / Fast,Custom,Medium,Explained Variance,Explained Variance (Higher-is-Better),Latent structure representation,Explained Variance (Higher-is-Better) -  Factor importance
Unsupervised - Dimensionality Reduction,Isomap,Preserving geodesic distances,Manifold learning,sklearn.manifold,Handwritten digit reduction,"n_neighbors, n_components",Medium / Medium,Visualization use,Medium,Geodesic Distance,Qualitative,Manifold structure preservation,Isomap ‚Äì Geodesic manifold structure
Unsupervised - Anomaly Detection,Isolation Forest,Outlier isolation,Random subspace partitioning,sklearn.ensemble,Fraud detection,"n_estimators, contamination",Fast / Fast,Flask,Medium,Anomaly Score,Anomaly Score (Higher-is-Better),Outlier probability,Anomaly Score (Higher-is-Better) -  Isolation depth
Unsupervised - Anomaly Detection,One-Class SVM,Boundary-based anomaly detection,Support vector hypersphere,sklearn.svm,Network intrusion detection,"nu, kernel",Slow / Medium,Rarely deployed,High,Anomaly Score,Anomaly Score (Higher-is-Better),Distance from boundary,Anomaly Score (Higher-is-Better) -  Deviation severity
Unsupervised - Anomaly Detection,Elliptic Envelope,Robust Gaussian anomaly detection,Elliptic covariance estimation,sklearn.covariance,Financial anomaly detection,"contamination, support_fraction",Fast / Fast,Rarely deployed,Medium,Mahalanobis Distance,Distance (Lower-is-Better),Outlier scoring by Gaussian envelope,Distance(Lower-is-Better) - Proximity to Gaussian center
Unsupervised - Anomaly Detection,Autoencoder-Based Anomaly Detection,Reconstruction error outliers,Undercomplete encoder-decoder,"keras, pytorch",IoT sensor fault detection,"encoding_dim, epochs",Slow / Fast,TensorFlow Serving,High,Reconstruction Error,Reconstruction Error (Higher-is-Better),Deviation from reconstruction,Reconstruction Error (Higher-is-Better) -  Error = Anomaly
Unsupervised - Anomaly Detection,Local Outlier Factor (LOF),Density-based anomaly detection,Local reachability density,sklearn.neighbors,Credit card fraud,n_neighbors,Medium / Fast,Rarely deployed,Medium,LOF Score,LOF Score (Higher-is-Better),Relative local density deviation,LOF Score (Higher-is-Better) -  Local rarity indicator
Deep Learning - Neural Network,Feedforward Neural Network (FNN),"Tabular data, regression/classification","Fully connected layers, backpropagation","tensorflow, keras, pytorch",Sales forecasting,"hidden_layers, activation, optimizer",Slow / Fast,"TensorFlow Serving, ONNX",High,"Accuracy, Cross-Entropy, MSE","Accuracy (Higher-is-Better), Cross-Entropy (Lower-is-Better), MSE (Lower-is-Better)",General classification or regression tasks,"Accuracy (Higher-is-Better) -  Prediction accuracy
Cross-Entropy(Lower-is-Better) - Class confidence loss
MSE(Lower-is-Better) - Avg error"
Deep Learning - Neural Network,Convolutional Neural Network (CNN),"Image data, spatial hierarchies","Convolutions, pooling, padding","tensorflow, pytorch, torchvision",Medical image classification,"filters, kernel_size, strides",Slow / Fast,TensorFlow Serving,High,"Accuracy, IOU","Accuracy (Higher-is-Better), IOU (Higher-is-Better)",Image-level prediction and object overlap,"Accuracy (Higher-is-Better) -  Classification score
IOU (Higher-is-Better) -  Bounding box overlap"
Deep Learning - Neural Network,Recurrent Neural Network (RNN),"Sequential data, time series","Temporal memory, vanishing gradients","tensorflow, keras, pytorch",Weather prediction,"hidden_size, sequence_length",Slow / Medium,TensorFlow Serving,High,"Accuracy, F1","Accuracy (Higher-is-Better), F1 (Higher-is-Better)",Sequence prediction quality,"Accuracy (Higher-is-Better) -  Match to sequence output
F1 (Higher-is-Better) -  Precision-recall balance"
Deep Learning - Neural Network,Long Short-Term Memory (LSTM),Long-sequence memory modeling,"Cell state, forget gates","tensorflow, keras, pytorch",Speech recognition,"units, dropout",Slow / Medium,TensorFlow Serving,High,"Accuracy, F1","Accuracy (Higher-is-Better), F1 (Higher-is-Better)",Improved sequence retention,"Accuracy (Higher-is-Better) -  Long-term prediction accuracy
F1 (Higher-is-Better) -  Sequential balance"
Deep Learning - Neural Network,Gated Recurrent Unit (GRU),Efficient sequence learning,Gates for reset/update,"tensorflow, keras, pytorch",Text generation,"units, dropout",Slow / Medium,TensorFlow Serving,High,"Accuracy, F1","Accuracy (Higher-is-Better), F1 (Higher-is-Better)",Simplified LSTM performance,"Accuracy (Higher-is-Better) -  Seq model accuracy
F1 (Higher-is-Better) -  Balance measure"
Deep Learning - Neural Network,Encoder-Decoder Architecture,Seq2Seq problems,Encoding-decoding bottleneck,"tensorflow, pytorch",Machine translation,"encoder_units, decoder_units",Slow / Medium,TensorFlow Serving,High,"BLEU Score, Accuracy","BLEU (Higher-is-Better), Accuracy (Higher-is-Better)",Translation or sequence generation,"BLEU (Higher-is-Better) -  Translation quality
Accuracy (Higher-is-Better) -  Prediction match"
Deep Learning - Neural Network,Transformer,Long-range sequence modeling,"Attention, positional encoding","transformers, huggingface",Language modeling,"num_heads, layers, d_model",Very Slow / Fast,"ONNX, Hugging Face Hub",Very High,"Accuracy, Perplexity","Accuracy (Higher-is-Better), Perplexity (Lower-is-Better)",Contextual understanding,"Accuracy (Higher-is-Better) -  Task accuracy
Perplexity(Lower-is-Better) - Uncertainty"
Deep Learning - Neural Network,ResNet,Deep convolutional learning,"Skip connections, residuals","tensorflow, pytorch",Image classification,"depth, block_type",Slow / Fast,TensorFlow Serving,High,"Accuracy, Top-1 Error","Accuracy (Higher-is-Better), Top-1 Error (Lower-is-Better)",Deeper networks without vanishing gradients,"Accuracy (Higher-is-Better) -  Correct label
Top-1 Error(Lower-is-Better) - Misclass rate"
Deep Learning - Neural Network,UNet,Semantic segmentation,Contracting-expanding paths,"tensorflow, pytorch",Medical image segmentation,"filters, depth",Slow / Fast,"ONNX, TorchServe",High,"Dice Coefficient, IOU","Dice (Higher-is-Better), IOU (Higher-is-Better)",Pixel-wise prediction,"Dice (Higher-is-Better) -  Overlap with mask
IOU (Higher-is-Better) -  Intersection-over-union"
Deep Learning - Neural Network,"Autoencoders (Basic, Denoising, Variational)",Compression and reconstruction,Encoder-decoder bottleneck,"keras, pytorch","Dimensionality reduction, anomaly detection","encoding_dim, latent_dim",Slow / Fast,TensorFlow Serving,High,Reconstruction Error,Reconstruction Error (Lower-is-Better),Loss between input and reconstructed output,Reconstruction Error(Lower-is-Better) - Loss due to compression
Generative AI - Text & Language,GPT (Generative Pretrained Transformer),"Text generation, completion","Autoregressive transformer, pretraining","openai, transformers","Chatbots, writing assistants","num_layers, max_length, temperature",Slow / Fast,"Hugging Face, OpenAI API",Very High,"Perplexity, BLEU, Accuracy","Perplexity (Lower-is-Better), BLEU (Higher-is-Better), Accuracy (Higher-is-Better)",Language understanding and generation quality,"Perplexity(Lower-is-Better) - Token uncertainty
BLEU (Higher-is-Better) -  Translation accuracy
Accuracy (Higher-is-Better) -  Correct language predictions"
Generative AI - Text & Language,"BERT, RoBERTa, ALBERT",Contextual understanding,"Bidirectional transformer, masked LM","transformers, huggingface","Q&A, Sentiment Analysis","hidden_size, attention_heads",Slow / Fast,Hugging Face,High,"Accuracy, F1","Accuracy (Higher-is-Better), F1 (Higher-is-Better)",Contextualized predictions and classification,"Accuracy (Higher-is-Better) -  Token/task prediction
F1 (Higher-is-Better) -  Precision/recall balance"
Generative AI - Text & Language,T5 (Text-to-Text Transfer Transformer),Multi-task NLP,Encoder-decoder transformer,"transformers, huggingface","Summarization, Translation","num_layers, d_model",Slow / Fast,Hugging Face,Very High,"BLEU, ROUGE, Accuracy","BLEU (Higher-is-Better), ROUGE (Higher-is-Better), Accuracy (Higher-is-Better)",Task-to-text conversion quality,"BLEU (Higher-is-Better) -  Translation quality
ROUGE (Higher-is-Better) -  Summary quality
Accuracy (Higher-is-Better) -  Task fit"
Generative AI - Text & Language,BART,Denoising autoencoder for sequence-to-sequence,"Encoder-decoder, noising","transformers, huggingface","Summarization, Translation","num_layers, dropout",Slow / Fast,Hugging Face,Very High,"BLEU, ROUGE","BLEU (Higher-is-Better), ROUGE (Higher-is-Better)",Sequence generation quality,"BLEU (Higher-is-Better) -  Fluent output
ROUGE (Higher-is-Better) -  Summary overlap"
Generative AI - Text & Language,"LLaMA, Falcon, Claude",Large-scale pretraining,"Transformer architecture, instruction tuning","transformers, huggingface","Chat interfaces, Content generation","num_layers, context_length",Very Slow / Fast,"Hugging Face, APIs",Very High,"Accuracy, Perplexity","Accuracy (Higher-is-Better), Perplexity (Lower-is-Better)",Instruction-following and generation,"Accuracy (Higher-is-Better) -  Output alignment
Perplexity(Lower-is-Better) - Confidence of generation"
Generative AI - Vision,"DALL¬∑E, MidJourney, Stable Diffusion",Text-to-image generation,"Diffusion models, latent spaces","diffusers, stability-ai, replicate","AI Art, Image Synthesis","guidance_scale, steps",Slow / Medium,"API-based, Local Inference",Very High,"FID Score, CLIP Score","FID (Lower-is-Better), CLIP (Higher-is-Better)",Visual coherence and relevance,"FID(Lower-is-Better) - Realism
CLIP (Higher-is-Better) -  Image-text alignment"
Generative AI - Vision,"StyleGAN, BigGAN, CycleGAN",Realistic image generation,Adversarial training,"tensorflow, pytorch","Face generation, Domain translation","latent_dim, num_blocks",Slow / Medium,"Docker, TorchServe",High,"Inception Score, FID","Inception (Higher-is-Better), FID (Lower-is-Better)",Visual realism and diversity,"Inception (Higher-is-Better) -  Diversity
FID(Lower-is-Better) - Realism"
Generative AI - Vision,CLIP,Vision-language understanding,Contrastive learning,"openai, clip-retrieval","Image search, Text-guided vision",embedding_dim,Fast / Fast,"Hugging Face, API",High,Zero-Shot Accuracy,Accuracy (Higher-is-Better),Cross-modal understanding,Accuracy (Higher-is-Better) -  Match between text and image
Generative AI - Multimodal,Flamingo (DeepMind),Visual-language fusion,Vision encoder + causal decoder,"deepmind, huggingface",Interactive Q&A,"num_layers, dim_head",Very Slow / Fast,"API, Research demo",Very High,"Accuracy, BLEU","Accuracy (Higher-is-Better), BLEU (Higher-is-Better)",Multimodal understanding and response,"Accuracy (Higher-is-Better) -  Output match
BLEU (Higher-is-Better) -  Text quality"
Generative AI - Multimodal,Gato (DeepMind),Generalist agent,Single transformer for many modalities,deepmind,"Control, vision, language","context_size, transformer_layers",Very Slow / Fast,Not public,Very High,Task Score,Score (Higher-is-Better),Unified multimodal control,Score (Higher-is-Better) -  General agent performance
Generative AI - Multimodal,"Gemini, Kosmos-1",Foundation models,"Multimodal, multilingual","google, microsoft",Multilingual AI agents,"layers, embedding_dim",Very Slow / Fast,"API, Cloud-based",Very High,Multimodal Accuracy,Accuracy (Higher-is-Better),General reasoning across inputs,Accuracy (Higher-is-Better) -  Reasoning ability
Reinforcement Learning - Value-Based,Q-Learning,Learning state-action values,"Tabular method, Bellman equation","gym, numpy","Gridworld, Game AI","learning_rate, discount_factor",Medium / Fast,Custom scripts,Medium,Cumulative Reward,Reward (Higher-is-Better),Measures total rewards received,Reward (Higher-is-Better) -  Long-term return
Reinforcement Learning - Value-Based,SARSA,On-policy learning,Updates using current policy,"gym, numpy",Robot navigation,"learning_rate, epsilon",Medium / Fast,Custom,Medium,Cumulative Reward,Reward (Higher-is-Better),Expected future reward from current policy,Reward (Higher-is-Better) -  Policy-followed performance
Reinforcement Learning - Deep Value-Based,Deep Q-Network (DQN),Scalable Q-Learning,Neural net approximator for Q-values,"stable-baselines3, keras-rl",Atari games,"epsilon_decay, replay_buffer_size",Slow / Medium,"Docker, TorchServe",High,Average Episode Reward,Reward (Higher-is-Better),Learned performance through gameplay,Reward (Higher-is-Better) -  Better actions over time
Reinforcement Learning - Policy-Based,Policy Gradient Methods,Optimizing stochastic policies,Gradient ascent on expected rewards,"tensorflow, pytorch",Continuous control tasks,"learning_rate, entropy_coef",Slow / Medium,Custom,High,Episode Return,Return (Higher-is-Better),Expected return from actions,Return (Higher-is-Better) -  Policy quality
Reinforcement Learning - Hybrid,Actor-Critic,Combines value & policy updates,Two networks: actor & critic,stable-baselines3,Robotic arm control,"gamma, advantage_fn",Slow / Medium,"Docker, TensorFlow",High,Total Reward,Reward (Higher-is-Better),Cumulative performance signal,Reward (Higher-is-Better) -  Balanced learning
Reinforcement Learning - Policy-Based,Proximal Policy Optimization (PPO),Stable policy updates,"Clipped objective, on-policy learning","stable-baselines3, ray[rllib]",Simulated environments,"clip_range, n_steps",Slow / Medium,"Docker, Cloud",High,"Episode Return, Reward Variance","Return (Higher-is-Better), Variance (Lower-is-Better)",Stability and performance,"Return (Higher-is-Better) -  Gains
Variance(Lower-is-Better) - Policy stability"
Reinforcement Learning - Policy-Based,Trust Region Policy Optimization (TRPO),Trust region for safe updates,KL divergence constrained learning,"rllab, garage",Simulated robotics,"max_kl, cg_iters",Slow / Medium,Custom,Very High,Average Reward,Reward (Higher-is-Better),Safeguarded learning updates,Reward (Higher-is-Better) -  Effective exploration
Reinforcement Learning - Hybrid,"Advantage Actor Critic (A2C, A3C)",Parallelized actor-critic,Shared model for multiple environments,"baselines, torch-ac",OpenAI gym tasks,"value_loss_coef, entropy_coef",Slow / Medium,Custom / Distributed,High,Total Return,Return (Higher-is-Better),Faster & distributed learning,Return (Higher-is-Better) -  Converged training efficiency
Reinforcement Learning - Model-Free,Monte Carlo Methods,Learning via episodic return,Delayed reward assignment,"gym, custom",Small MDPs,"episode_length, discount",Fast / Medium,Scripts,Medium,Average Return,Return (Higher-is-Better),Accuracy of return estimates,Return (Higher-is-Better) -  Learning from full episodes
Reinforcement Learning - Temporal Difference,"TD-Learning (TD(0), TD(Œª))",Bootstrapped return prediction,Combines Monte Carlo & Bellman,"gym, numpy",Simple MDPs,"lambda, alpha",Fast / Fast,Local,Medium,Mean TD Error,TD Error (Lower-is-Better),Error in expected returns,TD Error(Lower-is-Better) - Estimate refinement
Graph ML,Graph Neural Networks (GNN),"Node classification, link prediction","Message passing, neighborhood aggregation","dgl, pytorch-geometric",Social network analysis,"num_layers, hidden_dim",Slow / Medium,"TorchServe, Docker",High,"Accuracy, F1","Accuracy (Higher-is-Better), F1 (Higher-is-Better)",Node-wise prediction performance,"Accuracy (Higher-is-Better) -  Node label match
F1 (Higher-is-Better) -  Balanced metric"
Graph ML,Graph Convolutional Networks (GCN),Graph-structured learning,Spectral convolutions on graphs,"dgl, pytorch-geometric",Citation networks,"hidden_units, dropout",Slow / Medium,TorchServe,High,Accuracy,Accuracy (Higher-is-Better),Node classification correctness,Accuracy (Higher-is-Better) -  Label prediction match
Graph ML,Graph Attention Networks (GAT),Attention over neighbors,Self-attention on graph nodes,"dgl, pytorch-geometric",Knowledge graphs,"num_heads, dropout",Slow / Medium,"Docker, TorchServe",High,"Accuracy, F1","Accuracy (Higher-is-Better), F1 (Higher-is-Better)",Context-aware prediction quality,"Accuracy (Higher-is-Better) -  Correct classification
F1 (Higher-is-Better) -  Performance measure"
Graph ML,Graph Autoencoders,"Graph embedding, reconstruction",Encoder-decoder on graphs,pytorch-geometric,"Graph compression, link prediction","embedding_dim, learning_rate",Medium / Fast,Custom,Medium,Reconstruction Error,Error (Lower-is-Better),How well the graph is encoded,Error(Lower-is-Better) - Embedding quality
Graph ML,DeepWalk,Unsupervised node embedding,Random walks + Word2Vec,"stellargraph, gensim",Community detection,"walk_length, window_size",Fast / Fast,Custom pipeline,Medium,Embedding Similarity,Similarity (Higher-is-Better),Closeness in embedding space,Similarity (Higher-is-Better) -  Proximity in learned space
Graph ML,Node2Vec / Edge2Vec,Biased random walks for embedding,Flexible walk sampling strategy,"stellargraph, nodevectors",Graph recommendation,"p, q, dimensions",Fast / Fast,"Flask, Custom",Medium,Link Prediction Accuracy,Accuracy (Higher-is-Better),Link prediction via embeddings,Accuracy (Higher-is-Better) -  True edge prediction
Graph ML,"Knowledge Graph Embeddings (TransE, TransR)",Triple representation in low-dim space,Translation-based embedding,"ampligraph, openKE",Knowledge base completion,"embedding_dim, margin",Medium / Medium,"API, Custom",High,"MRR, Hits@K","MRR (Higher-is-Better), Hits@K (Higher-is-Better)",Entity and relation prediction,"MRR (Higher-is-Better) -  Rank avg.
Hits@K (Higher-is-Better) -  Top-K inclusion"
Probabilistic / Bayesian,Bayesian Networks,Probabilistic reasoning,"Directed acyclic graphs, conditional probabilities","pgmpy, pomegranate","Medical diagnosis, Fraud detection","structure_type, prior_type",Medium / Medium,"Custom, Flask",Medium,"Log-Likelihood, Accuracy","Log-Likelihood (Higher-is-Better), Accuracy (Higher-is-Better)",Joint probability modeling,"Log-Likelihood (Higher-is-Better) -  Model fit
Accuracy (Higher-is-Better) -  Prediction performance"
Probabilistic / Bayesian,Hidden Markov Models (HMM),Sequential probabilistic modeling,State transition + emission probabilities,"hmmlearn, pomegranate","Speech recognition, POS tagging","n_components, covariance_type",Medium / Medium,"Flask, Pickle",Medium,Log-Likelihood,Log-Likelihood (Higher-is-Better),Likelihood of observed sequences,Log-Likelihood (Higher-is-Better) -  Sequence plausibility
Probabilistic / Bayesian,Markov Decision Processes (MDP),Planning with decision uncertainty,"States, actions, rewards, transitions",pymdptoolbox,Robot path planning,"gamma, policy_eval_method",Medium / Medium,Custom,Medium,Cumulative Reward,Reward (Higher-is-Better),Expected return with policy,Reward (Higher-is-Better) -  Optimal policy evaluation
Probabilistic / Bayesian,Gaussian Processes (GP),Non-parametric regression/classification,Bayesian inference over functions,"GPy, scikit-learn",Time-series prediction,"kernel, alpha",Slow / Medium,"ONNX, Flask",High,"Log-Marginal Likelihood, RMSE","Likelihood (Higher-is-Better), RMSE (Lower-is-Better)",Uncertainty-aware predictions,"Log-Marginal Likelihood (Higher-is-Better) -  Fit
RMSE(Lower-is-Better) - Prediction error"
Probabilistic / Bayesian,Probabilistic Graphical Models,Flexible probabilistic inference,Graph-based probability distributions,"pgmpy, pyro",Causal inference,"graph_structure, inference_method",Medium / Medium,Custom,High,"Log-Likelihood, Accuracy","Log-Likelihood (Higher-is-Better), Accuracy (Higher-is-Better)",Joint inference over variables,"Log-Likelihood (Higher-is-Better) -  Data fit
Accuracy (Higher-is-Better) -  Output confidence"
Ensemble,"Bagging (e.g., Random Forest)",Reduce variance through averaging,"Bootstrap sampling, parallel trees",sklearn.ensemble,"Credit scoring, Churn prediction","n_estimators, max_features",Medium / Fast,"Flask, Docker",Medium,"Accuracy, AUC","Accuracy (Higher-is-Better), AUC (Higher-is-Better)",Improved stability and reduced overfitting,"Accuracy (Higher-is-Better) -  Majority vote accuracy
AUC (Higher-is-Better) -  Class separability"
Ensemble,"Boosting (e.g., AdaBoost, XGBoost)",Reduce bias through sequential correction,"Weighted voting, Residual fitting","xgboost, lightgbm, catboost","Fraud detection, Click prediction","learning_rate, n_estimators",Slow / Fast,"MLflow, Docker",High,"Accuracy, LogLoss, AUC","Accuracy (Higher-is-Better), LogLoss (Lower-is-Better), AUC (Higher-is-Better)",Accurate and interpretable boosting,"Accuracy (Higher-is-Better) -  Overall prediction
LogLoss(Lower-is-Better) - Confidence calibration
AUC (Higher-is-Better) -  ROC performance"
Ensemble,Stacking (Stacked Generalization),Meta-model learning over base learners,Blend diverse models using a meta-learner,"sklearn.ensemble, mlxtend",Complex tabular data,"base_models, final_estimator",Slow / Medium,"Custom, Docker",High,"Accuracy, AUC","Accuracy (Higher-is-Better), AUC (Higher-is-Better)",Combines strengths of multiple models,"Accuracy (Higher-is-Better) -  Combined model accuracy
AUC (Higher-is-Better) -  Aggregate separability"
Ensemble,Voting Classifier/Regressor,Majority (classification) / Mean (regression),Hard or soft voting over models,sklearn.ensemble,General purpose ensembling,"voting, weights",Fast / Fast,"Flask, Pickle",Medium,"Accuracy, R2","Accuracy (Higher-is-Better), R2 (Higher-is-Better)",Simple model averaging,"Accuracy (Higher-is-Better) -  Voting correctness
R2 (Higher-is-Better) -  Explained variance"
Ensemble,Blending,Holdout blending of predictions,Validation set-based meta-learner,"mlxtend, custom code","Competitions, Kaggle","blend_ratio, holdout_split",Medium / Medium,Custom,Medium,"Accuracy, AUC","Accuracy (Higher-is-Better), AUC (Higher-is-Better)",Heuristic model stacking,"Accuracy (Higher-is-Better) -  Final prediction quality
AUC (Higher-is-Better) -  Class separability"
Explainability Techniques,SHAP,Global + local feature attribution,"Game theory, model-agnostic",shap,"Finance, healthcare","explainer_type, background_data",Medium / Medium,"Streamlit, Jupyter",Medium,SHAP Value Magnitude,Magnitude(Higher-is-Better),Contribution of features to prediction,SHAP (Higher-is-Better) - Impact of each feature on prediction
Explainability Techniques,LIME,Local surrogate explanations,Linear approximation around prediction,lime,"Model debugging, Trust building","kernel_width, num_features",Medium / Medium,Not production-ready,Medium,Feature Weights,Magnitude(Higher-is-Better),Feature influence on specific prediction,LIME (Higher-is-Better) - Local feature importance
Explainability Techniques,Integrated Gradients,Attribution in neural networks,Path integral of gradients,"captum, tensorflow","Vision, NLP","steps, baseline",Slow / Medium,"TensorBoard, Captum",High,Attribution Score,Magnitude(Higher-is-Better),Importance of input features,Attribution (Higher-is-Better) - Influence of input on output
Explainability Techniques,Permutation Importance,Global importance measure,Randomly permute each feature,sklearn.inspection,Any tabular model,n_repeats,Fast / Fast,"Jupyter, Streamlit",Low,Importance Score,Score(Higher-is-Better),Effect of shuffling features on accuracy,Importance Score (Higher-is-Better) - Impact of permuted features
Explainability Techniques,PDP,Visualizing feature impact,Marginal effect of features,sklearn.inspection,Tabular feature analysis,grid_resolution,Fast / Medium,"Streamlit, Jupyter",Medium,PDP Curve,Qualitative,Effect of one or two features on prediction,PDP - Response surface visualization